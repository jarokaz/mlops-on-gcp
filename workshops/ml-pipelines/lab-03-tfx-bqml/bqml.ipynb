{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Y9PnAH1lVUtx"
   },
   "source": [
    "##### Copyright &copy; 2020 Google Inc.\n",
    "\n",
    "<font size=-1>Licensed under the Apache License, Version 2.0 (the \\\"License\\\");\n",
    "you may not use this file except in compliance with the License.\n",
    "You may obtain a copy of the License at [https://www.apache.org/licenses/LICENSE-2.0](https://www.apache.org/licenses/LICENSE-2.0)\n",
    "\n",
    "Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an \\\"AS IS\\\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  See the License for the specific language governing permissions and limitations under the License.</font>\n",
    "<hr/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4ny1E3iZVUtz"
   },
   "source": [
    "# Orchestrating BQML training and deployment with Managed Pipelines\n",
    "\n",
    "This notebook demonstrates how to use custom Python function-based components together with TFX standard components. In the notebook, you will orchestrate training and deployment of a BQML logistic regression model. \n",
    "\n",
    "1. BigQuery is used to prepare training data by executing an arbitrary SQL query and writing the results to a BigQuery table\n",
    "2. The table with training data is used to train a BQML logistic regression model \n",
    "3. The model is deployed to AI Platform Prediction for online serving"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upgrade BigQuery client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install --upgrade --user google-cloud-core==1.3.0 google-cloud-bigquery==1.26.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import IPython\n",
    "\n",
    "IPython.Application.instance().kernel.do_shutdown(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import the requiried libraries and verify a version of TFX SDK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import tensorflow as tf\n",
    "import tensorflow_data_validation as tfdv\n",
    "import tensorflow_model_analysis as tfma\n",
    "import tfx\n",
    "\n",
    "import logging\n",
    "import google.cloud\n",
    "\n",
    "from typing import Optional, Text, List, Dict, Any\n",
    "\n",
    "from ml_metadata.proto import metadata_store_pb2\n",
    "from tfx.components.base import executor_spec\n",
    "from tfx.components import Pusher\n",
    "from tfx.extensions.google_cloud_ai_platform.pusher import executor as ai_platform_pusher_executor\n",
    "\n",
    "print(\"Tensorflow Version:\", tf.__version__)\n",
    "print(\"TFX Version:\", tfx.__version__)\n",
    "print(\"TFDV Version:\", tfdv.__version__)\n",
    "print(\"TFMA Version:\", tfma.VERSION_STRING)\n",
    "print(\"BigQuery client:\", google.cloud.bigquery.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Update `PATH` with the location of TFX SDK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH=%env PATH\n",
    "%env PATH={PATH}:/home/jupyter/.local/bin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "u43xvtUaVUt2"
   },
   "source": [
    "### Configure GCP environment settings\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modify the below constants to reflect your environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT_ID = 'mlops-dev-env'\n",
    "REGION = 'us-central1'\n",
    "BUCKET_NAME = 'mlops-dev-workspace'  # Change this to your GCS bucket name.  Do not include the `gs://`.\n",
    "API_KEY =  '' # Change this to the API key that you created during initial setup\n",
    "BASE_IMAGE = 'gcr.io/caip-pipelines-assets/tfx:latest'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create an example BigQuery dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_LOCATION = 'US'\n",
    "DATASET_ID = 'covertype_dataset'\n",
    "TABLE_ID =' covertype'\n",
    "DATA_SOURCE = 'gs://workshop-datasets/covertype/small/dataset.csv'\n",
    "SCHEMA = 'Elevation:INTEGER,\\\n",
    "Aspect:INTEGER,\\\n",
    "Slope:INTEGER,\\\n",
    "Horizontal_Distance_To_Hydrology:INTEGER,\\\n",
    "Vertical_Distance_To_Hydrology:INTEGER,\\\n",
    "Horizontal_Distance_To_Roadways:INTEGER,\\\n",
    "Hillshade_9am:INTEGER,\\\n",
    "Hillshade_Noon:INTEGER,\\\n",
    "Hillshade_3pm:INTEGER,\\\n",
    "Horizontal_Distance_To_Fire_Points:INTEGER,\\\n",
    "Wilderness_Area:STRING,\\\n",
    "Soil_Type:STRING,\\\n",
    "Cover_Type:INTEGER'\n",
    "\n",
    "!bq --location=$DATASET_LOCATION --project_id=$PROJECT_ID mk --dataset $DATASET_ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!bq --project_id=$PROJECT_ID --dataset_id=$DATASET_ID load \\\n",
    "--source_format=CSV \\\n",
    "--skip_leading_rows=1 \\\n",
    "--replace \\\n",
    "$TABLE_ID \\\n",
    "$DATA_SOURCE \\\n",
    "$SCHEMA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WhUDXrmpVUub"
   },
   "source": [
    "## Create custom components\n",
    "\n",
    "In this section, we will create a set of custom omponents that encapsulate calls to BigQuery and BigQuery ML.\n",
    "\n",
    "### Create a data preprocessing component"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "j2LNuHOoVUub"
   },
   "outputs": [],
   "source": [
    "%%writefile preprocess_data.py\n",
    "\n",
    "import os\n",
    "import logging\n",
    "import uuid\n",
    "\n",
    "from google.cloud import bigquery\n",
    "\n",
    "from tfx.types.experimental.simple_artifacts import Dataset\n",
    "from tfx.dsl.component.experimental.decorators import component\n",
    "from tfx.dsl.component.experimental.annotations import OutputArtifact, Parameter\n",
    "\n",
    "@component\n",
    "def preprocess_data(\n",
    "    project_id: Parameter[str],\n",
    "    query: Parameter[str], \n",
    "    transformed_data: OutputArtifact[Dataset]):\n",
    "    \n",
    "    client = bigquery.Client(project=project_id)\n",
    "\n",
    "    dataset_name = f'{project_id}.bqml_demo_{uuid.uuid4().hex}'\n",
    "    table_name = f'{dataset_name}.{uuid.uuid4().hex}'\n",
    "    \n",
    "    dataset = bigquery.Dataset(dataset_name)\n",
    "    client.create_dataset(dataset)\n",
    "\n",
    "    job_config = bigquery.QueryJobConfig()\n",
    "    job_config.create_disposition = bigquery.job.CreateDisposition.CREATE_IF_NEEDED\n",
    "    job_config.write_disposition = bigquery.job.WriteDisposition.WRITE_TRUNCATE\n",
    "    job_config.destination = table_name\n",
    "\n",
    "    logging.info(f'Starting data preprocessing')\n",
    "    \n",
    "    query_job = client.query(query, job_config)\n",
    "    query_job.result() # Wait for the job to complete\n",
    "    \n",
    "    logging.info(f'Completed data preprocessing. Output in  {table_name}')\n",
    "    \n",
    "    # Write the location of the output table to metadata.  \n",
    "    transformed_data.set_string_custom_property('output_dataset', dataset_name)\n",
    "    transformed_data.set_string_custom_property('output_table', table_name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WhUDXrmpVUub"
   },
   "source": [
    "### Create a BQML training component"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "j2LNuHOoVUub"
   },
   "outputs": [],
   "source": [
    "%%writefile create_lr_model.py\n",
    "\n",
    "import os\n",
    "import logging\n",
    "\n",
    "from google.cloud import bigquery\n",
    "\n",
    "from tfx.types.experimental.simple_artifacts import Dataset\n",
    "from tfx.types.experimental.simple_artifacts import Model as BQModel\n",
    "from tfx.dsl.component.experimental.decorators import component\n",
    "from tfx.dsl.component.experimental.annotations import InputArtifact, OutputArtifact, Parameter\n",
    "\n",
    "@component\n",
    "def create_lr_model(\n",
    "    project_id: Parameter[str],\n",
    "    model_name: Parameter[str],\n",
    "    label_column: Parameter[str],\n",
    "    transformed_data: InputArtifact[Dataset],\n",
    "    model: OutputArtifact[BQModel]):\n",
    "    \n",
    "    dataset_name = transformed_data.get_string_custom_property('output_dataset')\n",
    "    table_name = transformed_data.get_string_custom_property('output_table')\n",
    "    model_name = f'{dataset_name}.{model_name}'\n",
    "    \n",
    "    query = f\"\"\"\n",
    "        CREATE OR REPLACE MODEL\n",
    "        `{model_name}`\n",
    "        OPTIONS\n",
    "          ( model_type='LOGISTIC_REG',\n",
    "            auto_class_weights=TRUE,\n",
    "            input_label_cols=['{label_column}']\n",
    "          ) AS\n",
    "        SELECT \n",
    "          *\n",
    "        FROM\n",
    "          `{table_name}`\n",
    "    \"\"\"\n",
    "    \n",
    "    client = bigquery.Client(project=project_id)\n",
    "\n",
    "    logging.info(f'Starting training of the model: {model_name}')\n",
    "    query_job = client.query(query)\n",
    "    query_job.result()\n",
    "    logging.info(f'Completed training of the model: {model_name}')\n",
    "    \n",
    "    # Write the location of the output table to metadata.  \n",
    "    model.set_string_custom_property('bq_model_name', model_name)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WhUDXrmpVUub"
   },
   "source": [
    "### Create a BQML model export component"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "j2LNuHOoVUub"
   },
   "outputs": [],
   "source": [
    "%%writefile export_model.py\n",
    "\n",
    "import os\n",
    "import logging\n",
    "import subprocess\n",
    "\n",
    "from google.cloud import bigquery\n",
    "\n",
    "from tfx.types.experimental.simple_artifacts import Dataset\n",
    "from tfx.types.experimental.simple_artifacts import Model as BQModel\n",
    "from tfx.types.standard_artifacts import Model\n",
    "from tfx.dsl.component.experimental.decorators import component\n",
    "from tfx.dsl.component.experimental.annotations import InputArtifact, OutputArtifact, Parameter\n",
    "\n",
    "\n",
    "@component\n",
    "def export_model(\n",
    "    bq_model: InputArtifact[BQModel],\n",
    "    model: OutputArtifact[Model]):\n",
    "    \n",
    "    bq_model_name = bq_model.get_string_custom_property('bq_model_name')\n",
    "    gcs_path = '{}/serving_model_dir'.format(model.uri.rstrip('/'))\n",
    "    \n",
    "    client = bigquery.Client()\n",
    "    bqml_model = bigquery.model.Model(bq_model_name)\n",
    "    \n",
    "    logging.info(f'Starting model extraction')\n",
    "    \n",
    "    extract_job = client.extract_table(bqml_model, gcs_path)\n",
    "    extract_job.result() # Wait for results\n",
    "    \n",
    "    logging.info(f'Model extraction completed')\n",
    "   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WhUDXrmpVUub"
   },
   "source": [
    "### Create an AI Platform Prediction deploy component\n",
    "\n",
    "This is an alternative to using the TFX Pusher component"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "j2LNuHOoVUub"
   },
   "outputs": [],
   "source": [
    "%%writefile deploy_model.py\n",
    "\n",
    "import os\n",
    "import logging\n",
    "import uuid\n",
    "\n",
    "import googleapiclient.discovery\n",
    "\n",
    "from tfx.types.standard_artifacts import Model\n",
    "from tfx.dsl.component.experimental.decorators import component\n",
    "from tfx.dsl.component.experimental.annotations import InputArtifact, OutputArtifact, Parameter\n",
    "\n",
    "@component\n",
    "def deploy_model(\n",
    "    project_id: Parameter[str],\n",
    "    model_name: Parameter[str],\n",
    "    runtime_version: Parameter[str],\n",
    "    python_version: Parameter[str],\n",
    "    framework: Parameter[str],\n",
    "    model: InputArtifact[Model]):\n",
    "    \n",
    "    service = googleapiclient.discovery.build('ml', 'v1')\n",
    "    version_name = f'v{uuid.uuid4().hex}'\n",
    "   \n",
    "    saved_model_path = '{}/serving_model_dir'.format(model.uri.rstrip('/'))\n",
    "    \n",
    "    project_path = f'projects/{project_id}'\n",
    "    model_path = f'{project_path}/models/{model_name}'\n",
    "    \n",
    "    response = service.projects().models().list(parent=project_path).execute()\n",
    "    if 'error' in response:\n",
    "        raise RuntimeError(response['error'])\n",
    "        \n",
    "\n",
    "    if not response or not [model['name'] for model in response['models'] if model['name'] == model_path]:\n",
    "        request_body={'name': model_name}\n",
    "        response = service.projects().models().create(parent=project_path, body=request_body).execute()\n",
    "        if 'error' in response:\n",
    "            raise RuntimeError(response['error'])\n",
    "        \n",
    "    request_body = {\n",
    "        \"name\": version_name,\n",
    "        \"deployment_uri\": saved_model_path,\n",
    "        \"machine_type\": \"n1-standard-8\",\n",
    "        \"runtime_version\": runtime_version,\n",
    "        \"python_version\": python_version,\n",
    "        \"framework\": framework\n",
    "    }\n",
    "    \n",
    "    logging.info(f'Starting model deployment')\n",
    "    response = service.projects().models().versions().create(parent=model_path, body=request_body).execute()\n",
    "    if 'error' in response:\n",
    "        raise RuntimeError(response['error'])\n",
    "    logging.info(f'Model deployed: {response}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Only required for local run.\n",
    "from tfx.orchestration.metadata import sqlite_metadata_connection_config\n",
    "\n",
    "from tfx.orchestration.pipeline import Pipeline\n",
    "from tfx.orchestration.ai_platform_pipelines import ai_platform_pipelines_dag_runner\n",
    "\n",
    "from preprocess_data import preprocess_data\n",
    "from create_lr_model import create_lr_model\n",
    "from export_model import export_model\n",
    "from deploy_model import deploy_model\n",
    "\n",
    "\n",
    "def bqml_pipeline(\n",
    "    pipeline_name: Text, \n",
    "    pipeline_root: Text, \n",
    "    query: Text, \n",
    "    project_id: Text, \n",
    "    model_name: Text, \n",
    "    label_column: Text,\n",
    "    metadata_connection_config: Optional[\n",
    "        metadata_store_pb2.ConnectionConfig] = None,\n",
    "    ai_platform_serving_args: Optional[Dict[Text, Any]] = None):\n",
    "    \n",
    "    components = []\n",
    "    \n",
    "    preprocess = preprocess_data(\n",
    "        query=query, \n",
    "        project_id=project_id)\n",
    "    components.append(preprocess)\n",
    "    \n",
    "    train = create_lr_model(\n",
    "        transformed_data=preprocess.outputs['transformed_data'],\n",
    "        project_id=project_id,\n",
    "        model_name=model_name,\n",
    "        label_column=label_column)\n",
    "    components.append(train)\n",
    "    \n",
    "    export = export_model(\n",
    "        bq_model=train.outputs['model']\n",
    "    )\n",
    "    components.append(export)\n",
    "    \n",
    "\n",
    "    if ai_platform_serving_args:\n",
    "        deploy = Pusher(\n",
    "            custom_executor_spec=executor_spec.ExecutorClassSpec(\n",
    "                ai_platform_pusher_executor.Executor),\n",
    "            model=export.outputs['model'],\n",
    "            custom_config={'ai_platform_serving_args': ai_platform_serving_args})\n",
    "        components.append(deploy)\n",
    "\n",
    "# The alternative using a custom deploy_model component\n",
    "#    if ai_platform_serving_args:\n",
    "#        deploy = deploy_model(\n",
    "#            project_id=project_id,\n",
    "#            runtime_version=ai_platform_serving_args['runtimeVersion'],\n",
    "#            python_version=ai_platform_serving_args['pythonVersion'],\n",
    "#            framework=ai_platform_serving_args['framework'],\n",
    "#            model_name=ai_platform_serving_args['model_name'],\n",
    "#            model=export.outputs['model']\n",
    "#        )\n",
    "        #components.append(deploy)\n",
    "    \n",
    "    return Pipeline(\n",
    "        pipeline_name=pipeline_name,\n",
    "        pipeline_root=pipeline_root,\n",
    "        metadata_connection_config=metadata_connection_config,\n",
    "        components=components\n",
    "      )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the pipeline locally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tfx.orchestration.beam.beam_dag_runner import BeamDagRunner\n",
    "\n",
    "query = 'SELECT * FROM `mlops-dev-env.covertype_dataset.covertype` LIMIT 1000'\n",
    "label_column = 'Cover_Type'\n",
    "model_name = 'covertype_classifier'\n",
    "pipeline_root = 'gs://{}/pipeline_root/{}'.format(BUCKET_NAME, 'bqml-test2')\n",
    "pipeline_name = 'bqml-pipeline'\n",
    "\n",
    "metadata_connection_config=sqlite_metadata_connection_config('metadata.sqlite')\n",
    "\n",
    "ai_platform_serving_args = {\n",
    "      'project_id': PROJECT_ID,\n",
    "      'model_name': 'CovertypeBQMLLocal',\n",
    "      'runtimeVersion': '1.15',\n",
    "      'pythonVersion': '3.7',\n",
    "      'framework': 'TENSORFLOW'}\n",
    "\n",
    "logging.getLogger().setLevel(logging.INFO)\n",
    "\n",
    "BeamDagRunner().run(bqml_pipeline(\n",
    "        pipeline_name=pipeline_name,\n",
    "        pipeline_root=pipeline_root,\n",
    "        query=query,\n",
    "        project_id=PROJECT_ID,\n",
    "        model_name=model_name,\n",
    "        label_column=label_column,\n",
    "        metadata_connection_config=metadata_connection_config,\n",
    "        ai_platform_serving_args=ai_platform_serving_args))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check that the metadata was produced locally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LzGf0xH8VUvL"
   },
   "outputs": [],
   "source": [
    "from ml_metadata import metadata_store\n",
    "from ml_metadata.proto import metadata_store_pb2\n",
    "\n",
    "connection_config = metadata_store_pb2.ConnectionConfig()\n",
    "connection_config.sqlite.filename_uri = 'metadata.sqlite'\n",
    "connection_config.sqlite.connection_mode = 3 # READWRITE_OPENCREATE\n",
    "store = metadata_store.MetadataStore(connection_config)\n",
    "store.get_artifacts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the pipeline in Managed Pipelines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7ynW6qhXVUug"
   },
   "source": [
    "### Package the components into a custom docker image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "y4KCoSe3VUuv"
   },
   "source": [
    "Next, let's package the above into a container.   \n",
    "In future, it will be possible to do this via the TFX CLI. For now, we'll do this using a Dockerfile and Skaffold. \n",
    "\n",
    "> Note: If you're running this notebook on AI Platform Notebooks, Docker will be installed.  If you're running the notebook in a local development environment, you'll need to have Docker installed there. Confirm that you have [installed Skaffold](https://skaffold.dev/docs/install/) locally as well.\n",
    "\n",
    "First, we'll define a `skaffold.yaml` file.  We'll first define a string to use in creating the file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wRz7udPaVUuw"
   },
   "outputs": [],
   "source": [
    "tag = 'demo'\n",
    "\n",
    "SK_TEMPLATE = \"{{{{.IMAGE_NAME}}}}:{}\".format(tag)\n",
    "print(SK_TEMPLATE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6h2CR9MUVUuy"
   },
   "source": [
    "Now we'll write out the Skaffold yaml file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QkXyPriaVUuz"
   },
   "outputs": [],
   "source": [
    "image_name = f'gcr.io/{PROJECT_ID}/caip-tfx-bqml'\n",
    "\n",
    "skaffold_template = f\"\"\"\n",
    "apiVersion: skaffold/v2beta3\n",
    "kind: Config\n",
    "metadata:\n",
    "  name: my-pipeline\n",
    "build:\n",
    "  artifacts:\n",
    "  - image: '{image_name}'\n",
    "    context: .\n",
    "    docker:\n",
    "      dockerfile: Dockerfile\n",
    "  tagPolicy:\n",
    "    envTemplate:\n",
    "      template: \"{{SK_TEMPLATE}}\"\n",
    "\"\"\"\n",
    "with open('skaffold.yaml', 'w') as f:\n",
    "    f.write(skaffold_template.format(**globals()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3O63tfpaVUu3"
   },
   "source": [
    "Next, we'll define the `Dockerfile`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qE8TDTPTVUu3"
   },
   "outputs": [],
   "source": [
    "%%writefile Dockerfile\n",
    "FROM gcr.io/caip-pipelines-assets/tfx:latest\n",
    "RUN pip install --upgrade google-cloud-core==1.3.0 google-cloud-bigquery==1.26.1\n",
    "WORKDIR /pipeline\n",
    "COPY *.py ./\n",
    "ENV PYTHONPATH=\"/pipeline:${PYTHONPATH}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oPwDxVUKVUu9"
   },
   "outputs": [],
   "source": [
    "!skaffold build"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submit a run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = 'SELECT * FROM `mlops-dev-env.covertype_dataset.covertype` LIMIT 1000'\n",
    "\n",
    "label_column = 'Cover_Type'\n",
    "model_name = 'covertype_classifier'\n",
    "pipeline_name = 'bqml-pipeline-tests'\n",
    "pipeline_root = 'gs://{}/pipeline_root/{}'.format(BUCKET_NAME, pipeline_name)\n",
    "ai_platform_serving_args = {\n",
    "      'project_id': PROJECT_ID,\n",
    "      'model_name': 'CovertypeBQMLtest',\n",
    "      'runtimeVersion': '1.15',\n",
    "      'pythonVersion': '3.7',\n",
    "      'framework': 'TENSORFLOW'}\n",
    "\n",
    "pipeline = bqml_pipeline(\n",
    "        pipeline_name=pipeline_name,\n",
    "        pipeline_root=pipeline_root,\n",
    "        query=query,\n",
    "        project_id=PROJECT_ID,\n",
    "        model_name=model_name,\n",
    "        label_column=label_column,\n",
    "        ai_platform_serving_args=ai_platform_serving_args)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DCeOo5vKVUxi"
   },
   "outputs": [],
   "source": [
    "config = ai_platform_pipelines_dag_runner.AIPlatformPipelinesDagRunnerConfig(\n",
    "    project_id=PROJECT_ID,\n",
    "    display_name=pipeline_name,\n",
    "    default_image=f'{image_name}:{tag}')\n",
    "\n",
    "runner = ai_platform_pipelines_dag_runner.AIPlatformPipelinesDagRunner(config=config)\n",
    "runner.run(pipeline, api_key=API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "caipp_eap_custom.ipynb",
   "provenance": [
    {
     "file_id": "17Ye1xgZiHyVx1Fd_4JqDyq2fprYuWhvg",
     "timestamp": 1592238906065
    }
   ],
   "toc_visible": true
  },
  "environment": {
   "name": "tf2-2-3-gpu.2-3.m55",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-2-3-gpu.2-3:m55"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
