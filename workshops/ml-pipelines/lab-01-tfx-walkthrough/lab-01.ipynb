{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TFX Components Walk-through"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning Objectives\n",
    "\n",
    "1.  Develop a high level understanding of TFX pipeline components.\n",
    "2.  Learn how to use a TFX Interactive Context for prototype development of TFX pipelines.\n",
    "3.  Work with the Tensorflow Data Validation (TFDV) library to check and analyze input data.\n",
    "4.  Utilize the Tensorflow Transform (TFT) library for scalable data preprocessing and feature transformations.\n",
    "5.  Employ the Tensorflow Model Analysis (TFMA) library for model evaluation.\n",
    "\n",
    "In this lab, you will work with the [Covertype Data Set](https://github.com/jarokaz/mlops-labs/blob/master/datasets/covertype/README.md) and use TFX to analyze, understand, and pre-process the dataset and train, analyze, validate, and deploy a multi-class classification model to predict the type of forest cover from cartographic features.\n",
    "\n",
    "\n",
    "**Setup Note:**\n",
    "Currently, TFMA visualizations do not render properly in JupyterLab. It is recommended to run this notebook in Jupyter Classic Notebook. To switch to Classic Notebook select *Launch Classic Notebook* from the *Help* menu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import absl\n",
    "import os\n",
    "import tempfile\n",
    "import time\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_data_validation as tfdv\n",
    "import tensorflow_model_analysis as tfma\n",
    "import tensorflow_transform as tft\n",
    "import tfx\n",
    "\n",
    "from pprint import pprint\n",
    "from tensorflow_metadata.proto.v0 import schema_pb2, statistics_pb2, anomalies_pb2\n",
    "from tensorflow_transform.tf_metadata import schema_utils\n",
    "\n",
    "from ml_metadata.metadata_store import metadata_store\n",
    "from ml_metadata.proto import metadata_store_pb2\n",
    "\n",
    "from tfx.components import CsvExampleGen\n",
    "from tfx.components import Evaluator\n",
    "from tfx.components import ExampleValidator\n",
    "from tfx.components import InfraValidator\n",
    "from tfx.components import Pusher\n",
    "from tfx.components import ResolverNode\n",
    "from tfx.components import SchemaGen\n",
    "from tfx.components import StatisticsGen\n",
    "from tfx.components import Trainer\n",
    "from tfx.components import Transform\n",
    "from tfx.components.base import executor_spec\n",
    "from tfx.components.common_nodes.importer_node import ImporterNode\n",
    "from tfx.components.trainer import executor as trainer_executor\n",
    "\n",
    "from tfx.dsl.experimental import latest_blessed_model_resolver\n",
    "\n",
    "from tfx.orchestration.beam.beam_dag_runner import BeamDagRunner\n",
    "from tfx.orchestration.ai_platform_pipelines import ai_platform_pipelines_dag_runner\n",
    "from tfx.orchestration.metadata import sqlite_metadata_connection_config\n",
    "from tfx.orchestration.pipeline import Pipeline\n",
    "from tfx.orchestration import metadata\n",
    "\n",
    "from tfx.proto import evaluator_pb2\n",
    "from tfx.proto import example_gen_pb2\n",
    "from tfx.proto import infra_validator_pb2\n",
    "from tfx.proto import pusher_pb2\n",
    "from tfx.proto import trainer_pb2\n",
    "from tfx.proto.evaluator_pb2 import SingleSlicingSpec\n",
    "\n",
    "from tfx.utils.dsl_utils import external_input\n",
    "\n",
    "from tfx.types import Channel\n",
    "from tfx.types.standard_artifacts import Examples\n",
    "from tfx.types.standard_artifacts import ExampleStatistics\n",
    "from tfx.types.standard_artifacts import ExampleAnomalies\n",
    "from tfx.types.standard_artifacts import Model\n",
    "from tfx.types.standard_artifacts import ModelEvaluation\n",
    "from tfx.types.standard_artifacts import ModelBlessing\n",
    "from tfx.types.standard_artifacts import InfraBlessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up the environment\n",
    "### Verify TFX SDK Version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**: this lab was developed and tested with the following TF ecosystem package versions:\n",
    "\n",
    "`Tensorflow Version: 2.3.0`  \n",
    "`TFX Version: 0.23.0.caip20200818`  \n",
    "`TFDV Version: 0.23.0`  \n",
    "`TFMA Version: 0.23.0`\n",
    "\n",
    "If you encounter errors with the above imports (e.g. TFX component not found), check your package versions in the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorflow Version: 2.3.0\n",
      "TFX Version: 0.23.0.caip20200818\n",
      "TFDV Version: 0.23.0\n",
      "TFMA Version: 0.23.0\n"
     ]
    }
   ],
   "source": [
    "print(\"Tensorflow Version:\", tf.__version__)\n",
    "print(\"TFX Version:\", tfx.__version__)\n",
    "print(\"TFDV Version:\", tfdv.__version__)\n",
    "print(\"TFMA Version:\", tfma.VERSION_STRING)\n",
    "\n",
    "absl.logging.set_verbosity(absl.logging.INFO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the versions above do not match, update your packages in the current Jupyter kernel. \n",
    "\n",
    "### Update `PATH` with the location of TFX SDK."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['PATH'] += os.pathsep + '/home/jupyter/.local/bin'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configure lab settings\n",
    "\n",
    "Set constants, location paths and other environment settings. \n",
    "\n",
    "### Settings for Beam runner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOCAL_PIPELINE_ROOT= os.path.join(os.sep, 'home', 'jupyter', 'pipeline-root')\n",
    "METADATA_PATH = os.path.join(LOCAL_PIPELINE_ROOT, 'metadata.sqlite')\n",
    "SERVING_MODEL_DIR =os.path.join(os.sep, 'home', 'jupyter', 'serving_model')\n",
    "metadata_connection_config=sqlite_metadata_connection_config(METADATA_PATH)\n",
    "connection_config = metadata_store_pb2.ConnectionConfig()\n",
    "connection_config.sqlite.filename_uri = METADATA_PATH\n",
    "connection_config.sqlite.connection_mode = 3 # READWRITE_OPENCREATE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Settings for Managed Pipelines runner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT_ID = 'mlops-dev-env'\n",
    "GCS_BUCKET_NAME = 'mlops-dev-workspace'\n",
    "GCS_PIPELINE_ROOT = f'gs://{GCS_BUCKET_NAME}/pipeline-root'\n",
    "BASE_IMAGE = f'gcr.io/caip-pipelines-assets/tfx:{tfx.__version__}'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Source dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_ROOT = 'gs://workshop-datasets/covertype/small'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configure TFX Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ingesting data using ExampleGen\n",
    "\n",
    "In any ML development process the first step  is to ingest the training and test datasets. The `ExampleGen` component ingests data into a TFX pipeline. It consumes external files/services to generate a set file files in the `TFRecord` format,  which will be used by other TFX components. It can also shuffle the data and split into an arbitrary number of partitions.\n",
    "\n",
    "<img src=https://github.com/GoogleCloudPlatform/mlops-on-gcp/raw/master/images/ExampleGen.png width=\"300\">\n",
    "\n",
    "\n",
    "In this exercise, you use the `CsvExampleGen` specialization of `ExampleGen` to ingest CSV files from a GCS location. The component is configured to split the input data into two splits - `train` and `eval` - using 4:1 ratio.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "output_config = example_gen_pb2.Output(\n",
    "    split_config=example_gen_pb2.SplitConfig(splits=[\n",
    "        example_gen_pb2.SplitConfig.Split(name='train', hash_buckets=4),\n",
    "        example_gen_pb2.SplitConfig.Split(name='eval', hash_buckets=1)\n",
    "    ]))\n",
    "\n",
    "example_gen = tfx.components.CsvExampleGen(\n",
    "    instance_name='Data_Extraction_Spliting',\n",
    "    input_base=DATA_ROOT,\n",
    "    output_config=output_config\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create a simple pipeline to test the component"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pipeline_name = 'example_gen_only'\n",
    "components = [example_gen]\n",
    "\n",
    "pipeline = Pipeline(\n",
    "    pipeline_name=pipeline_name,\n",
    "    pipeline_root=f'{LOCAL_PIPELINE_ROOT}/{pipeline_name}',\n",
    "    metadata_connection_config=metadata_connection_config,\n",
    "    components=components\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:apache_beam.runners.interactive.interactive_environment:Dependencies required for Interactive Beam PCollection visualization are not available, please use: `pip install apache-beam[interactive]` to install necessary dependencies to enable all data visualization features.\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "        if (typeof window.interactive_beam_jquery == 'undefined') {\n",
       "          var jqueryScript = document.createElement('script');\n",
       "          jqueryScript.src = 'https://code.jquery.com/jquery-3.4.1.slim.min.js';\n",
       "          jqueryScript.type = 'text/javascript';\n",
       "          jqueryScript.onload = function() {\n",
       "            var datatableScript = document.createElement('script');\n",
       "            datatableScript.src = 'https://cdn.datatables.net/1.10.20/js/jquery.dataTables.min.js';\n",
       "            datatableScript.type = 'text/javascript';\n",
       "            datatableScript.onload = function() {\n",
       "              window.interactive_beam_jquery = jQuery.noConflict(true);\n",
       "              window.interactive_beam_jquery(document).ready(function($){\n",
       "                \n",
       "              });\n",
       "            }\n",
       "            document.head.appendChild(datatableScript);\n",
       "          };\n",
       "          document.head.appendChild(jqueryScript);\n",
       "        } else {\n",
       "          window.interactive_beam_jquery(document).ready(function($){\n",
       "            \n",
       "          });\n",
       "        }"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "        var import_html = () => {\n",
       "          ['https://raw.githubusercontent.com/PAIR-code/facets/1.0.0/facets-dist/facets-jupyter.html'].forEach(href => {\n",
       "            var link = document.createElement('link');\n",
       "            link.rel = 'import'\n",
       "            link.href = href;\n",
       "            document.head.appendChild(link);\n",
       "          });\n",
       "        }\n",
       "        if ('import' in document.createElement('link')) {\n",
       "          import_html();\n",
       "        } else {\n",
       "          var webcomponentScript = document.createElement('script');\n",
       "          webcomponentScript.src = 'https://cdnjs.cloudflare.com/ajax/libs/webcomponentsjs/1.3.3/webcomponents-lite.js';\n",
       "          webcomponentScript.type = 'text/javascript';\n",
       "          webcomponentScript.onload = function(){\n",
       "            import_html();\n",
       "          };\n",
       "          document.head.appendChild(webcomponentScript);\n",
       "        }"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:absl:Component CsvExampleGen.Data_Extraction_Spliting depends on [].\n",
      "INFO:absl:Component CsvExampleGen.Data_Extraction_Spliting is scheduled.\n",
      "INFO:absl:Component CsvExampleGen.Data_Extraction_Spliting is running.\n",
      "INFO:absl:Running driver for CsvExampleGen.Data_Extraction_Spliting\n",
      "INFO:absl:MetadataStore with DB connection initialized\n",
      "INFO:absl:select span and version = (0, None)\n",
      "INFO:absl:latest span and version = (0, None)\n",
      "INFO:absl:Running executor for CsvExampleGen.Data_Extraction_Spliting\n",
      "INFO:absl:Generating examples.\n",
      "INFO:absl:Processing input csv data gs://workshop-datasets/covertype/small/* to TFExample.\n",
      "WARNING:apache_beam.io.tfrecordio:Couldn't find python-snappy so the implementation of _TFRecordUtil._masked_crc32c is not as fast as it could be.\n",
      "INFO:absl:Examples generated.\n",
      "INFO:absl:Running publisher for CsvExampleGen.Data_Extraction_Spliting\n",
      "INFO:absl:MetadataStore with DB connection initialized\n",
      "INFO:absl:Component CsvExampleGen.Data_Extraction_Spliting is finished.\n"
     ]
    }
   ],
   "source": [
    "BeamDagRunner().run(pipeline)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Examine artifacts generated by the pipeline run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:absl:MetadataStore with DB connection initialized\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jupyter/pipeline-root/example_gen_only/CsvExampleGen.Data_Extraction_Spliting/examples/1\n",
      "{'split_names': string_value: \"[\\\"train\\\", \\\"eval\\\"]\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "with metadata.Metadata(connection_config) as store:\n",
    "    examples_artifacts = store.get_artifacts_by_type(Examples.TYPE_NAME)\n",
    "\n",
    "for element in examples_artifacts:\n",
    "    print(element.uri)\n",
    "    print(element.properties)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Examine the ingested data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hillshade_3pm: [157]\n",
      "Horizontal_Distance_To_Fire_Points: [1871]\n",
      "Hillshade_Noon: [247]\n",
      "Hillshade_9am: [223]\n",
      "Aspect: [183]\n",
      "Horizontal_Distance_To_Hydrology: [648]\n",
      "Elevation: [3142]\n",
      "Horizontal_Distance_To_Roadways: [757]\n",
      "Slope: [9]\n",
      "Wilderness_Area: [b'Commanche']\n",
      "Vertical_Distance_To_Hydrology: [101]\n",
      "Soil_Type: [b'C7757']\n",
      "Cover_Type: [1]\n",
      "******\n",
      "Aspect: [124]\n",
      "Hillshade_9am: [245]\n",
      "Horizontal_Distance_To_Hydrology: [60]\n",
      "Slope: [16]\n",
      "Elevation: [1967]\n",
      "Horizontal_Distance_To_Roadways: [124]\n",
      "Wilderness_Area: [b'Cache']\n",
      "Vertical_Distance_To_Hydrology: [9]\n",
      "Cover_Type: [2]\n",
      "Soil_Type: [b'C2704']\n",
      "Hillshade_3pm: [105]\n",
      "Hillshade_Noon: [227]\n",
      "Horizontal_Distance_To_Fire_Points: [451]\n",
      "******\n"
     ]
    }
   ],
   "source": [
    "examples_uri = examples_artifacts[-1].uri\n",
    "tfrecord_filenames = [os.path.join(examples_uri, 'train', name)\n",
    "                      for name in os.listdir(os.path.join(examples_uri, 'train'))]\n",
    "dataset = tf.data.TFRecordDataset(tfrecord_filenames, compression_type=\"GZIP\")\n",
    "for tfrecord in dataset.take(2):\n",
    "  example = tf.train.Example()\n",
    "  example.ParseFromString(tfrecord.numpy())\n",
    "  for name, feature in example.features.feature.items():\n",
    "    if feature.HasField('bytes_list'):\n",
    "        value = feature.bytes_list.value\n",
    "    if feature.HasField('float_list'):\n",
    "        value = feature.float_list.value\n",
    "    if feature.HasField('int64_list'):\n",
    "        value = feature.int64_list.value\n",
    "    print('{}: {}'.format(name, value))\n",
    "  print('******')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating statistics using StatisticsGen\n",
    "\n",
    "The `StatisticsGen`  component generates data statistics that can be used by other TFX components. StatisticsGen uses [TensorFlow Data Validation](https://www.tensorflow.org/tfx/data_validation/get_started). `StatisticsGen` generate statistics for each split in the `ExampleGen` component's output. In our case there two splits: `train` and `eval`.\n",
    "\n",
    "<img src=https://github.com/GoogleCloudPlatform/mlops-on-gcp/raw/master/images/StatisticsGen.png width=\"200\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:absl:Excluding no splits because exclude_splits is not set.\n"
     ]
    }
   ],
   "source": [
    "statistics_gen = tfx.components.StatisticsGen(\n",
    "    instance_name='Statistics_Generation',\n",
    "    examples=example_gen.outputs['examples'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Infering data schema using SchemaGen\n",
    "\n",
    "Some TFX components use a description input data called a schema. The schema is an instance of `schema.proto`. It can specify data types for feature values, whether a feature has to be present in all examples, allowed value ranges, and other properties. `SchemaGen` automatically generates the schema by inferring types, categories, and ranges from data statistics. The auto-generated schema is best-effort and only tries to infer basic properties of the data. It is expected that developers review and modify it as needed. `SchemaGen` uses [TensorFlow Data Validation](https://www.tensorflow.org/tfx/data_validation/get_started).\n",
    "\n",
    "The `SchemaGen` component generates the schema using the statistics for the `train` split. The statistics for other splits are ignored.\n",
    "\n",
    "<img src=https://github.com/GoogleCloudPlatform/mlops-on-gcp/raw/master/images/SchemaGen.png width=\"200\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:absl:Excluding no splits because exclude_splits is not set.\n"
     ]
    }
   ],
   "source": [
    "schema_gen = SchemaGen(\n",
    "    statistics=statistics_gen.outputs['statistics'],\n",
    "    infer_feature_shape=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validating data with ExampleValidator\n",
    "\n",
    "The `ExampleValidator` component identifies anomalies in data.  It identifies anomalies by comparing data statistics computed by the `StatisticsGen` component against a schema generated by `SchemaGen` or imported by `ImporterNode`.\n",
    "\n",
    "`ExampleValidator` can detect different classes of anomalies. For example it can:\n",
    "\n",
    "- perform validity checks by comparing data statistics against a schema \n",
    "- detect training-serving skew by comparing training and serving data.\n",
    "- detect data drift by looking at a series of data.\n",
    "\n",
    "\n",
    "The `ExampleValidator` component validates the data in the `eval` split only. Other splits are ignored. \n",
    "\n",
    "<img src=https://github.com/GoogleCloudPlatform/mlops-on-gcp/raw/master/images/ExampleValidator.png width=\"350\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:absl:Excluding no splits because exclude_splits is not set.\n"
     ]
    }
   ],
   "source": [
    "example_validator = ExampleValidator(\n",
    "    statistics=statistics_gen.outputs['statistics'],\n",
    "    schema=schema_gen.outputs['schema'],\n",
    "    instance_name=\"Data_Validation\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing data with Transform\n",
    "\n",
    "The `Transform` component performs data transformation and feature engineering. The `Transform` component consumes `tf.Examples` emitted from the `ExampleGen` component and emits the transformed feature data and the `SavedModel` graph that was used to process the data. The emitted `SavedModel`  can then be used by serving components to make sure that the same data pre-processing logic is applied at training and serving.\n",
    "\n",
    "The `Transform` component requires more code than many other components because of the arbitrary complexity of the feature engineering that you may need for the data and/or model that you're working with. It requires code files to be available which define the processing needed.\n",
    "\n",
    "<img src=https://github.com/GoogleCloudPlatform/mlops-on-gcp/raw/master/images/Transform.png width=\"400\">\n",
    "\n",
    "#### Define the pre-processing module\n",
    "\n",
    "To configure `Trainsform`, you need to encapsulate your pre-processing code in the Python `preprocessing_fn` function and save it to a  python module that is then provided to the Transform component as an input. This module will be loaded by transform and the `preprocessing_fn` function will be called when the `Transform` component runs.\n",
    "\n",
    "In most cases, your implementation of the `preprocessing_fn` makes extensive use of [TensorFlow Transform](https://www.tensorflow.org/tfx/guide/tft) for performing feature engineering on your dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "FEATURES_MODULE = 'features.py'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting features.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile {FEATURES_MODULE}\n",
    "# Copyright 2020 Google LLC. All Rights Reserved.\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "\"\"\"Covertype model  taxi model features.\"\"\"\n",
    "import tensorflow as tf\n",
    "import tensorflow_model_analysis as tfma\n",
    "import tensorflow_transform as tft\n",
    "from tensorflow_transform.tf_metadata import schema_utils\n",
    "\n",
    "NUMERIC_FEATURE_KEYS = [\n",
    "    'Elevation', 'Aspect', 'Slope', 'Horizontal_Distance_To_Hydrology',\n",
    "    'Vertical_Distance_To_Hydrology', 'Horizontal_Distance_To_Roadways',\n",
    "    'Hillshade_9am', 'Hillshade_Noon', 'Hillshade_3pm',\n",
    "    'Horizontal_Distance_To_Fire_Points'\n",
    "]\n",
    "\n",
    "CATEGORICAL_FEATURE_KEYS = ['Wilderness_Area', 'Soil_Type']\n",
    "\n",
    "LABEL_KEY = 'Cover_Type'\n",
    "NUM_CLASSES = 7\n",
    "\n",
    "def transformed_name(key):\n",
    "  return key + '_xf'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRANSFORM_MODULE = 'preprocessing.py'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting preprocessing.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile {TRANSFORM_MODULE}\n",
    "# Copyright 2020 Google LLC. All Rights Reserved.\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "\"\"\"Covertype preprocessing.\n",
    "This file defines a template for TFX Transform component.\n",
    "\"\"\"\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_transform as tft\n",
    "\n",
    "import features\n",
    "\n",
    "def _fill_in_missing(x):\n",
    "  \"\"\"Replace missing values in a SparseTensor.\n",
    "  Fills in missing values of `x` with '' or 0, and converts to a dense tensor.\n",
    "  Args:\n",
    "    x: A `SparseTensor` of rank 2.  Its dense shape should have size at most 1\n",
    "      in the second dimension.\n",
    "  Returns:\n",
    "    A rank 1 tensor where missing values of `x` have been filled in.\n",
    "  \"\"\"\n",
    "  default_value = '' if x.dtype == tf.string else 0\n",
    "  return tf.squeeze(\n",
    "      tf.sparse.to_dense(\n",
    "          tf.SparseTensor(x.indices, x.values, [x.dense_shape[0], 1]),\n",
    "          default_value),\n",
    "      axis=1)\n",
    "\n",
    "def preprocessing_fn(inputs):\n",
    "  \"\"\"Preprocesses Covertype Dataset.\"\"\"\n",
    "\n",
    "  outputs = {}\n",
    "\n",
    "  # Scale numerical features\n",
    "  for key in features.NUMERIC_FEATURE_KEYS:\n",
    "    outputs[features.transformed_name(key)] = tft.scale_to_z_score(\n",
    "        _fill_in_missing(inputs[key]))\n",
    "\n",
    "  # Generate vocabularies and maps categorical features\n",
    "  for key in features.CATEGORICAL_FEATURE_KEYS:\n",
    "    outputs[features.transformed_name(key)] = tft.compute_and_apply_vocabulary(\n",
    "        x=_fill_in_missing(inputs[key]), num_oov_buckets=1, vocab_filename=key)\n",
    "\n",
    "  # Convert Cover_Type to dense tensor\n",
    "  outputs[features.transformed_name(features.LABEL_KEY)] = _fill_in_missing(\n",
    "      inputs[features.LABEL_KEY])\n",
    "\n",
    "  return outputs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Configure the component."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Only one of `artifacts` and `matching_channel_name` should be set.\n"
     ]
    }
   ],
   "source": [
    "transform = Transform(\n",
    "    examples=example_gen.outputs['examples'],\n",
    "    schema=schema_gen.outputs['schema'],\n",
    "    module_file=TRANSFORM_MODULE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train with the `Trainer` component\n",
    "\n",
    "The `Trainer` component trains a model using TensorFlow.\n",
    "\n",
    "`Trainer` takes:\n",
    "\n",
    "- tf.Examples used for training and eval.\n",
    "- A user provided module file that defines the trainer logic.\n",
    "- A data schema created by `SchemaGen` or imported by `ImporterNode`.\n",
    "- A proto definition of train args and eval args.\n",
    "- An optional transform graph produced by upstream Transform component.\n",
    "- An optional base models used for scenarios such as warmstart.\n",
    "\n",
    "<img src=https://github.com/GoogleCloudPlatform/mlops-on-gcp/raw/master/images/Trainer.png width=\"400\">\n",
    "\n",
    "\n",
    "#### Define the trainer module\n",
    "\n",
    "To configure `Trainer`, you need to encapsulate your training code in a Python module that is then provided to the `Trainer` as an input. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAINER_MODULE_FILE = 'model.py'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting model.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile {TRAINER_MODULE_FILE}\n",
    "# Copyright 2020 Google LLC. All Rights Reserved.\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "\"\"\"The Covertype classifier DNN keras model.\"\"\"\n",
    "\n",
    "import absl\n",
    "import os\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_model_analysis as tfma\n",
    "import tensorflow_transform as tft\n",
    "from tensorflow_transform.tf_metadata import schema_utils\n",
    "\n",
    "import features\n",
    "\n",
    "HIDDEN_UNITS = [16, 8]\n",
    "LEARNING_RATE = 0.001\n",
    "TRAIN_BATCH_SIZE = 64\n",
    "EVAL_BATCH_SIZE = 64\n",
    "\n",
    "LOCAL_LOG_DIR = '/tmp/logs'\n",
    "\n",
    "\n",
    "def _gzip_reader_fn(filenames):\n",
    "  \"\"\"Small utility returning a record reader that can read gzip'ed files.\"\"\"\n",
    "  return tf.data.TFRecordDataset(filenames, compression_type='GZIP')\n",
    "\n",
    "\n",
    "def _get_serve_tf_examples_fn(model, tf_transform_output):\n",
    "  \"\"\"Returns a function that parses a serialized tf.Example and applies TFT.\"\"\"\n",
    "\n",
    "  model.tft_layer = tf_transform_output.transform_features_layer()\n",
    "\n",
    "  @tf.function\n",
    "  def serve_tf_examples_fn(serialized_tf_examples):\n",
    "    \"\"\"Returns the output to be used in the serving signature.\"\"\"\n",
    "    feature_spec = tf_transform_output.raw_feature_spec()\n",
    "    feature_spec.pop(features.LABEL_KEY)\n",
    "    parsed_features = tf.io.parse_example(serialized_tf_examples, feature_spec)\n",
    "\n",
    "    transformed_features = model.tft_layer(parsed_features)\n",
    "\n",
    "    return model(transformed_features)\n",
    "\n",
    "  return serve_tf_examples_fn\n",
    "\n",
    "\n",
    "def _input_fn(file_pattern, tf_transform_output, batch_size=200):\n",
    "  \"\"\"Generates features and label for tuning/training.\n",
    "  Args:\n",
    "    file_pattern: input tfrecord file pattern.\n",
    "    tf_transform_output: A TFTransformOutput.\n",
    "    batch_size: representing the number of consecutive elements of returned\n",
    "      dataset to combine in a single batch\n",
    "  Returns:\n",
    "    A dataset that contains (features, indices) tuple where features is a\n",
    "      dictionary of Tensors, and indices is a single Tensor of label indices.\n",
    "  \"\"\"\n",
    "  transformed_feature_spec = (\n",
    "      tf_transform_output.transformed_feature_spec().copy())\n",
    "\n",
    "  dataset = tf.data.experimental.make_batched_features_dataset(\n",
    "      file_pattern=file_pattern,\n",
    "      batch_size=batch_size,\n",
    "      features=transformed_feature_spec,\n",
    "      reader=_gzip_reader_fn,\n",
    "      label_key=features.transformed_name(features.LABEL_KEY))\n",
    "\n",
    "  return dataset\n",
    "\n",
    "def _build_keras_model(tf_transform_output, hidden_units, learning_rate):\n",
    "  \"\"\"Creates a DNN Keras model for classifying taxi data.\n",
    "  Args:\n",
    "    hidden_units: [int], the layer sizes of the DNN (input layer first).\n",
    "  Returns:\n",
    "    A keras Model.\n",
    "  \"\"\"\n",
    "\n",
    "  numeric_columns = [\n",
    "      tf.feature_column.numeric_column(\n",
    "          key=features.transformed_name(key), \n",
    "          shape=())\n",
    "      for key in features.NUMERIC_FEATURE_KEYS\n",
    "  ]\n",
    "\n",
    "  categorical_columns = [\n",
    "      tf.feature_column.categorical_column_with_identity(\n",
    "          key=features.transformed_name(key), \n",
    "          num_buckets=tf_transform_output.num_buckets_for_transformed_feature(features.transformed_name(key)), \n",
    "          default_value=0)\n",
    "      for key in features.CATEGORICAL_FEATURE_KEYS\n",
    "  ]\n",
    "\n",
    "  indicator_columns = [\n",
    "      tf.feature_column.indicator_column(categorical_column)\n",
    "      for categorical_column in categorical_columns\n",
    "  ]\n",
    "\n",
    "  model = _wide_and_deep_classifier(\n",
    "      # TODO(b/139668410) replace with premade wide_and_deep keras model\n",
    "      wide_columns=indicator_columns,\n",
    "      deep_columns=numeric_columns,\n",
    "      dnn_hidden_units=hidden_units,\n",
    "      learning_rate=learning_rate)\n",
    "  return model\n",
    "\n",
    "\n",
    "def _wide_and_deep_classifier(wide_columns, deep_columns, dnn_hidden_units, learning_rate):\n",
    "  \"\"\"Builds a simple keras wide and deep model.\n",
    "  Args:\n",
    "    wide_columns: Feature columns wrapped in indicator_column for wide (linear)\n",
    "      part of the model.\n",
    "    deep_columns: Feature columns for deep part of the model.\n",
    "    dnn_hidden_units: [int], the layer sizes of the hidden DNN.\n",
    "  Returns:\n",
    "    A Wide and Deep Keras model\n",
    "  \"\"\"\n",
    "  \n",
    "  input_layers = {\n",
    "      column.key: tf.keras.layers.Input(name=column.key, shape=(), dtype=tf.float32)\n",
    "      for column in deep_columns\n",
    "  }\n",
    "  \n",
    "  input_layers.update({\n",
    "      column.categorical_column.key: tf.keras.layers.Input(name=column.categorical_column.key, shape=(), dtype=tf.int32)\n",
    "      for column in wide_columns\n",
    "  })\n",
    "    \n",
    "  deep = tf.keras.layers.DenseFeatures(deep_columns)(input_layers)\n",
    "  for numnodes in dnn_hidden_units:\n",
    "    deep = tf.keras.layers.Dense(numnodes)(deep)\n",
    "  wide = tf.keras.layers.DenseFeatures(wide_columns)(input_layers)\n",
    "\n",
    "  output = tf.keras.layers.Dense(features.NUM_CLASSES, activation='softmax')(\n",
    "               tf.keras.layers.concatenate([deep, wide]))\n",
    "\n",
    "  model = tf.keras.Model(input_layers, output)\n",
    "  model.compile(\n",
    "      loss='sparse_categorical_crossentropy',\n",
    "      optimizer=tf.keras.optimizers.Adam(lr=learning_rate),\n",
    "      metrics=[tf.keras.metrics.SparseCategoricalAccuracy()])\n",
    "  model.summary(print_fn=absl.logging.info)\n",
    "  return model\n",
    "\n",
    "def _copy_tensorboard_logs(local_path, saved_model_path):\n",
    "    \"\"\"Copies Tensorboard logs to the subfolder in the GCS SavedModel location.\"\"\"\n",
    "\n",
    "    if saved_model_path[0:5] == 'gs://':\n",
    "        pattern = '{}/*/events.out.tfevents.*'.format(local_path)\n",
    "        dest_path = saved_model_path.rstrip('/') + '/' + 'logs'\n",
    "        local_files = tf.io.gfile.glob(pattern)\n",
    "        dest_log_files = [local_file.replace(local_path, dest_path) for local_file in local_files]\n",
    "        for local_file, dest_file in zip(local_files, dest_log_files):\n",
    "            tf.io.gfile.copy(local_file, dest_file)\n",
    "\n",
    "# TFX Trainer will call this function.\n",
    "def run_fn(fn_args):\n",
    "  \"\"\"Trains a model based on given args.\n",
    "  Args:\n",
    "    fn_args: Holds args used to train the model as name/value pairs.\n",
    "  \"\"\"\n",
    "  \n",
    "  tf_transform_output = tft.TFTransformOutput(fn_args.transform_output)\n",
    "    \n",
    "  train_dataset = _input_fn(fn_args.train_files, tf_transform_output, TRAIN_BATCH_SIZE)\n",
    "  eval_dataset = _input_fn(fn_args.eval_files, tf_transform_output, EVAL_BATCH_SIZE)\n",
    "    \n",
    "  model = _build_keras_model(\n",
    "      tf_transform_output=tf_transform_output,\n",
    "      hidden_units=HIDDEN_UNITS,\n",
    "      learning_rate=LEARNING_RATE\n",
    "  )\n",
    "\n",
    "  tensorboard_callback = tf.keras.callbacks.TensorBoard(\n",
    "      log_dir=LOCAL_LOG_DIR, update_freq='batch')\n",
    "  callbacks = [ \n",
    "      tensorboard_callback\n",
    "  ]\n",
    "\n",
    "  model.fit(\n",
    "      train_dataset,\n",
    "      steps_per_epoch=fn_args.train_steps,\n",
    "      validation_data=eval_dataset,\n",
    "      validation_steps=fn_args.eval_steps,\n",
    "      verbose=2,\n",
    "      callbacks=callbacks)\n",
    "    \n",
    "  signatures = {\n",
    "      'serving_default':\n",
    "          _get_serve_tf_examples_fn(model,\n",
    "                                    tf_transform_output).get_concrete_function(\n",
    "                                        tf.TensorSpec(\n",
    "                                            shape=[None],\n",
    "                                            dtype=tf.string,\n",
    "                                            name='examples')),\n",
    "  }\n",
    "  \n",
    "  model.save(fn_args.serving_model_dir, save_format='tf', signatures=signatures)\n",
    "  _copy_tensorboard_logs(LOCAL_LOG_DIR, fn_args.serving_model_dir)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "As of the 0.23 release of TFX, the `Trainer` component only supports passing a single field - `num_steps` - through the `train_args` and `eval_args` arguments. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    custom_executor_spec=executor_spec.ExecutorClassSpec(trainer_executor.GenericExecutor),\n",
    "    module_file=TRAINER_MODULE_FILE,\n",
    "    transformed_examples=transform.outputs[\"transformed_examples\"],\n",
    "    schema=schema_gen.outputs[\"schema\"],\n",
    "    transform_graph=transform.outputs[\"transform_graph\"],\n",
    "    train_args=trainer_pb2.TrainArgs(num_steps=5000),\n",
    "    eval_args=trainer_pb2.EvalArgs(num_steps=1000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating trained models with Evaluator\n",
    "The `Evaluator` component analyzes model performance using the [TensorFlow Model Analysis library](https://www.tensorflow.org/tfx/model_analysis/get_started). It runs inference requests on particular subsets of the test dataset, based on which slices are defined by the developer. Knowing which slices should be analyzed requires domain knowledge of what is important in this particular use case or domain. \n",
    "\n",
    "The `Evaluator` can also optionally validate a newly trained model against a previous model. In this lab, you only train one model, so the Evaluator automatically will label the model as \"blessed\".\n",
    "\n",
    "\n",
    "<img src=https://github.com/GoogleCloudPlatform/mlops-on-gcp/raw/master/images/Evaluator.png width=\"400\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can use the `ResolverNode` to pick the previous model to compare against.  The model resolver is only required if performing model validation in addition to evaluation. In this case we validate against the latest blessed model. If no model has been blessed before (as in this case) the evaluator will make our candidate the first blessed model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_resolver = ResolverNode(\n",
    "      instance_name='latest_blessed_model_resolver',\n",
    "      resolver_class=latest_blessed_model_resolver.LatestBlessedModelResolver,\n",
    "      model=Channel(type=Model),\n",
    "      model_blessing=Channel(type=ModelBlessing))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Configure evaluation metrics and slices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "model_specs {\n",
       "  label_key: \"Cover_Type\"\n",
       "}\n",
       "slicing_specs {\n",
       "}\n",
       "slicing_specs {\n",
       "  feature_keys: \"Wilderness_Area\"\n",
       "}\n",
       "metrics_specs {\n",
       "  metrics {\n",
       "    class_name: \"SparseCategoricalAccuracy\"\n",
       "    threshold {\n",
       "      value_threshold {\n",
       "        lower_bound {\n",
       "          value: 0.5\n",
       "        }\n",
       "        upper_bound {\n",
       "          value: 0.99\n",
       "        }\n",
       "      }\n",
       "      change_threshold {\n",
       "        absolute {\n",
       "          value: 0.0001\n",
       "        }\n",
       "        direction: HIGHER_IS_BETTER\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "  metrics {\n",
       "    class_name: \"ExampleCount\"\n",
       "  }\n",
       "}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_threshold = tfma.MetricThreshold(\n",
    "                value_threshold=tfma.GenericValueThreshold(\n",
    "                    lower_bound={'value': 0.5},\n",
    "                    upper_bound={'value': 0.99}),\n",
    "                change_threshold=tfma.GenericChangeThreshold(\n",
    "                    absolute={'value': 0.0001},\n",
    "                    direction=tfma.MetricDirection.HIGHER_IS_BETTER),\n",
    "                )\n",
    "\n",
    "metrics_specs = tfma.MetricsSpec(\n",
    "                   metrics = [\n",
    "                       tfma.MetricConfig(class_name='SparseCategoricalAccuracy',\n",
    "                           threshold=accuracy_threshold),\n",
    "                       tfma.MetricConfig(class_name='ExampleCount')])\n",
    "\n",
    "eval_config = tfma.EvalConfig(\n",
    "    model_specs=[\n",
    "        tfma.ModelSpec(label_key='Cover_Type')\n",
    "    ],\n",
    "    metrics_specs=[metrics_specs],\n",
    "    slicing_specs=[\n",
    "        tfma.SlicingSpec(),\n",
    "        tfma.SlicingSpec(feature_keys=['Wilderness_Area'])\n",
    "    ]\n",
    ")\n",
    "eval_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_analyzer = Evaluator(\n",
    "    examples=example_gen.outputs.examples,\n",
    "    model=trainer.outputs.model,\n",
    "    baseline_model=model_resolver.outputs.model,\n",
    "    eval_config=eval_config\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### InfraValidator\n",
    "\n",
    "The `InfraValidator` component acts as an additional early warning layer by validating a candidate model in a sandbox version of its serving infrastructure to prevent an unservable model from being pushed to production. Compared to the `Evaluator` component above which validates a model's performance, the `InfraValidator` component is validating that a model is able to generate predictions from served examples in an environment configured to match production. The config below takes a model and examples, launches the model in a sand-boxed [TensorflowServing](https://www.tensorflow.org/tfx/guide/serving) model server from the latest image in a local docker engine, and optionally checks that the model binary can be loaded and queried before \"blessing\" it for production.\n",
    "\n",
    "<img src=https://github.com/GoogleCloudPlatform/mlops-on-gcp/raw/master/images/InfraValidator.png width=\"400\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "infra_validator = InfraValidator(\n",
    "    model=trainer.outputs['model'],\n",
    "    examples=example_gen.outputs['examples'],\n",
    "    serving_spec=infra_validator_pb2.ServingSpec(\n",
    "        tensorflow_serving=infra_validator_pb2.TensorFlowServing(\n",
    "            tags=['latest']),\n",
    "      local_docker=infra_validator_pb2.LocalDockerConfig(),\n",
    "  ),\n",
    "    validation_spec=infra_validator_pb2.ValidationSpec(\n",
    "        max_loading_time_seconds=60,\n",
    "        num_tries=5,\n",
    "    ),    \n",
    "  request_spec=infra_validator_pb2.RequestSpec(\n",
    "      tensorflow_serving=infra_validator_pb2.TensorFlowServingRequestSpec(),\n",
    "          num_examples=5,\n",
    "      )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deploying models with Pusher\n",
    "\n",
    "The `Pusher` component checks whether a model has been \"blessed\", and if so, deploys it by pushing the model to a well known file destination.\n",
    "\n",
    "<img src=https://github.com/GoogleCloudPlatform/mlops-on-gcp/raw/master/images/Pusher.png width=\"400\">\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "pusher = Pusher(\n",
    "    model=trainer.outputs['model'],\n",
    "    model_blessing=model_analyzer.outputs['blessing'],\n",
    "    infra_blessing=infra_validator.outputs['blessing'],\n",
    "    push_destination=pusher_pb2.PushDestination(\n",
    "        filesystem=pusher_pb2.PushDestination.Filesystem(\n",
    "            base_directory=SERVING_MODEL_DIR)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running the pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_name = 'covertype-end-to-end'\n",
    "components = [example_gen, \n",
    "              statistics_gen, \n",
    "              schema_gen,\n",
    "              example_validator,\n",
    "              transform,\n",
    "              trainer,\n",
    "              model_resolver,\n",
    "              model_analyzer,\n",
    "              infra_validator,\n",
    "              pusher]\n",
    "\n",
    "pipeline = Pipeline(\n",
    "    pipeline_name=pipeline_name,\n",
    "    pipeline_root=f'{LOCAL_PIPELINE_ROOT}/{pipeline_name}',\n",
    "    metadata_connection_config=metadata_connection_config,\n",
    "    components=components\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the pipeline locally using Beam Runner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:absl:Component CsvExampleGen.Data_Extraction_Spliting depends on [].\n",
      "INFO:absl:Component CsvExampleGen.Data_Extraction_Spliting is scheduled.\n",
      "INFO:absl:Component ResolverNode.latest_blessed_model_resolver depends on [].\n",
      "INFO:absl:Component ResolverNode.latest_blessed_model_resolver is scheduled.\n",
      "INFO:absl:Component StatisticsGen.Statistics_Generation depends on ['Run[CsvExampleGen.Data_Extraction_Spliting]'].\n",
      "INFO:absl:Component StatisticsGen.Statistics_Generation is scheduled.\n",
      "INFO:absl:Component SchemaGen depends on ['Run[StatisticsGen.Statistics_Generation]'].\n",
      "INFO:absl:Component SchemaGen is scheduled.\n",
      "INFO:absl:Component ExampleValidator.Data_Validation depends on ['Run[StatisticsGen.Statistics_Generation]', 'Run[SchemaGen]'].\n",
      "INFO:absl:Component ExampleValidator.Data_Validation is scheduled.\n",
      "INFO:absl:Component Transform depends on ['Run[CsvExampleGen.Data_Extraction_Spliting]', 'Run[SchemaGen]'].\n",
      "INFO:absl:Component Transform is scheduled.\n",
      "INFO:absl:Component Trainer depends on ['Run[Transform]', 'Run[SchemaGen]'].\n",
      "INFO:absl:Component Trainer is scheduled.\n",
      "INFO:absl:Component Evaluator depends on ['Run[Trainer]', 'Run[CsvExampleGen.Data_Extraction_Spliting]', 'Run[ResolverNode.latest_blessed_model_resolver]'].\n",
      "INFO:absl:Component Evaluator is scheduled.\n",
      "INFO:absl:Component InfraValidator depends on ['Run[Trainer]', 'Run[CsvExampleGen.Data_Extraction_Spliting]'].\n",
      "INFO:absl:Component InfraValidator is scheduled.\n",
      "INFO:absl:Component Pusher depends on ['Run[InfraValidator]', 'Run[Trainer]', 'Run[Evaluator]'].\n",
      "INFO:absl:Component Pusher is scheduled.\n",
      "INFO:absl:Component ResolverNode.latest_blessed_model_resolver is running.\n",
      "INFO:absl:Running driver for ResolverNode.latest_blessed_model_resolver\n",
      "INFO:absl:MetadataStore with DB connection initialized\n",
      "INFO:absl:Running publisher for ResolverNode.latest_blessed_model_resolver\n",
      "INFO:absl:MetadataStore with DB connection initialized\n",
      "INFO:absl:Component ResolverNode.latest_blessed_model_resolver is finished.\n",
      "INFO:absl:Component CsvExampleGen.Data_Extraction_Spliting is running.\n",
      "INFO:absl:Running driver for CsvExampleGen.Data_Extraction_Spliting\n",
      "INFO:absl:MetadataStore with DB connection initialized\n",
      "INFO:absl:select span and version = (0, None)\n",
      "INFO:absl:latest span and version = (0, None)\n",
      "INFO:absl:Running executor for CsvExampleGen.Data_Extraction_Spliting\n",
      "INFO:absl:Generating examples.\n",
      "INFO:absl:Processing input csv data gs://workshop-datasets/covertype/small/* to TFExample.\n",
      "INFO:absl:Examples generated.\n",
      "INFO:absl:Running publisher for CsvExampleGen.Data_Extraction_Spliting\n",
      "INFO:absl:MetadataStore with DB connection initialized\n",
      "INFO:absl:Component CsvExampleGen.Data_Extraction_Spliting is finished.\n",
      "INFO:absl:Component StatisticsGen.Statistics_Generation is running.\n",
      "INFO:absl:Running driver for StatisticsGen.Statistics_Generation\n",
      "INFO:absl:MetadataStore with DB connection initialized\n",
      "INFO:absl:Running executor for StatisticsGen.Statistics_Generation\n",
      "INFO:absl:We decided to produce LargeList and LargeBinary types.\n",
      "INFO:absl:We decided to produce LargeList and LargeBinary types.\n",
      "INFO:absl:Generating statistics for split train.\n",
      "INFO:absl:Statistics for split train written to /home/jupyter/pipeline-root/end-to-end/StatisticsGen.Statistics_Generation/statistics/4/train.\n",
      "INFO:absl:Generating statistics for split eval.\n",
      "INFO:absl:Statistics for split eval written to /home/jupyter/pipeline-root/end-to-end/StatisticsGen.Statistics_Generation/statistics/4/eval.\n",
      "INFO:absl:Running publisher for StatisticsGen.Statistics_Generation\n",
      "INFO:absl:MetadataStore with DB connection initialized\n",
      "INFO:absl:Component StatisticsGen.Statistics_Generation is finished.\n",
      "INFO:absl:Component SchemaGen is running.\n",
      "INFO:absl:Running driver for SchemaGen\n",
      "INFO:absl:MetadataStore with DB connection initialized\n",
      "INFO:absl:Running executor for SchemaGen\n",
      "INFO:absl:Processing schema from statistics for split train.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/jupyter/.local/lib/python3.7/site-packages/tensorflow_data_validation/utils/stats_util.py:229: tf_record_iterator (from tensorflow.python.lib.io.tf_record) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use eager execution and: \n",
      "`tf.data.TFRecordDataset(path)`\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:absl:Processing schema from statistics for split eval.\n",
      "INFO:absl:Schema written to /home/jupyter/pipeline-root/end-to-end/SchemaGen/schema/5/schema.pbtxt.\n",
      "INFO:absl:Running publisher for SchemaGen\n",
      "INFO:absl:MetadataStore with DB connection initialized\n",
      "INFO:absl:Component SchemaGen is finished.\n",
      "INFO:absl:Component Transform is running.\n",
      "INFO:absl:Running driver for Transform\n",
      "INFO:absl:MetadataStore with DB connection initialized\n",
      "INFO:absl:Running executor for Transform\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/jupyter/.local/lib/python3.7/site-packages/tfx/components/transform/executor.py:485: Schema (from tensorflow_transform.tf_metadata.dataset_schema) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Schema is a deprecated, use schema_utils.schema_from_feature_spec to create a `Schema`\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:absl:We decided to produce LargeList and LargeBinary types.\n",
      "INFO:absl:We decided to produce LargeList and LargeBinary types.\n",
      "INFO:absl:We decided to produce LargeList and LargeBinary types.\n",
      "INFO:absl:Feature Aspect has no shape. Setting to VarLenSparseTensor.\n",
      "INFO:absl:Feature Cover_Type has no shape. Setting to VarLenSparseTensor.\n",
      "INFO:absl:Feature Elevation has no shape. Setting to VarLenSparseTensor.\n",
      "INFO:absl:Feature Hillshade_3pm has no shape. Setting to VarLenSparseTensor.\n",
      "INFO:absl:Feature Hillshade_9am has no shape. Setting to VarLenSparseTensor.\n",
      "INFO:absl:Feature Hillshade_Noon has no shape. Setting to VarLenSparseTensor.\n",
      "INFO:absl:Feature Horizontal_Distance_To_Fire_Points has no shape. Setting to VarLenSparseTensor.\n",
      "INFO:absl:Feature Horizontal_Distance_To_Hydrology has no shape. Setting to VarLenSparseTensor.\n",
      "INFO:absl:Feature Horizontal_Distance_To_Roadways has no shape. Setting to VarLenSparseTensor.\n",
      "INFO:absl:Feature Slope has no shape. Setting to VarLenSparseTensor.\n",
      "INFO:absl:Feature Soil_Type has no shape. Setting to VarLenSparseTensor.\n",
      "INFO:absl:Feature Vertical_Distance_To_Hydrology has no shape. Setting to VarLenSparseTensor.\n",
      "INFO:absl:Feature Wilderness_Area has no shape. Setting to VarLenSparseTensor.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/jupyter/.local/lib/python3.7/site-packages/tensorflow_transform/tf_utils.py:218: Tensor.experimental_ref (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use ref() instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:absl:Feature Aspect has no shape. Setting to VarLenSparseTensor.\n",
      "INFO:absl:Feature Cover_Type has no shape. Setting to VarLenSparseTensor.\n",
      "INFO:absl:Feature Elevation has no shape. Setting to VarLenSparseTensor.\n",
      "INFO:absl:Feature Hillshade_3pm has no shape. Setting to VarLenSparseTensor.\n",
      "INFO:absl:Feature Hillshade_9am has no shape. Setting to VarLenSparseTensor.\n",
      "INFO:absl:Feature Hillshade_Noon has no shape. Setting to VarLenSparseTensor.\n",
      "INFO:absl:Feature Horizontal_Distance_To_Fire_Points has no shape. Setting to VarLenSparseTensor.\n",
      "INFO:absl:Feature Horizontal_Distance_To_Hydrology has no shape. Setting to VarLenSparseTensor.\n",
      "INFO:absl:Feature Horizontal_Distance_To_Roadways has no shape. Setting to VarLenSparseTensor.\n",
      "INFO:absl:Feature Slope has no shape. Setting to VarLenSparseTensor.\n",
      "INFO:absl:Feature Soil_Type has no shape. Setting to VarLenSparseTensor.\n",
      "INFO:absl:Feature Vertical_Distance_To_Hydrology has no shape. Setting to VarLenSparseTensor.\n",
      "INFO:absl:Feature Wilderness_Area has no shape. Setting to VarLenSparseTensor.\n",
      "INFO:absl:Feature Aspect has no shape. Setting to VarLenSparseTensor.\n",
      "INFO:absl:Feature Cover_Type has no shape. Setting to VarLenSparseTensor.\n",
      "INFO:absl:Feature Elevation has no shape. Setting to VarLenSparseTensor.\n",
      "INFO:absl:Feature Hillshade_3pm has no shape. Setting to VarLenSparseTensor.\n",
      "INFO:absl:Feature Hillshade_9am has no shape. Setting to VarLenSparseTensor.\n",
      "INFO:absl:Feature Hillshade_Noon has no shape. Setting to VarLenSparseTensor.\n",
      "INFO:absl:Feature Horizontal_Distance_To_Fire_Points has no shape. Setting to VarLenSparseTensor.\n",
      "INFO:absl:Feature Horizontal_Distance_To_Hydrology has no shape. Setting to VarLenSparseTensor.\n",
      "INFO:absl:Feature Horizontal_Distance_To_Roadways has no shape. Setting to VarLenSparseTensor.\n",
      "INFO:absl:Feature Slope has no shape. Setting to VarLenSparseTensor.\n",
      "INFO:absl:Feature Soil_Type has no shape. Setting to VarLenSparseTensor.\n",
      "INFO:absl:Feature Vertical_Distance_To_Hydrology has no shape. Setting to VarLenSparseTensor.\n",
      "INFO:absl:Feature Wilderness_Area has no shape. Setting to VarLenSparseTensor.\n",
      "INFO:absl:We decided to produce LargeList and LargeBinary types.\n",
      "INFO:absl:Feature Aspect has no shape. Setting to VarLenSparseTensor.\n",
      "INFO:absl:Feature Cover_Type has no shape. Setting to VarLenSparseTensor.\n",
      "INFO:absl:Feature Elevation has no shape. Setting to VarLenSparseTensor.\n",
      "INFO:absl:Feature Hillshade_3pm has no shape. Setting to VarLenSparseTensor.\n",
      "INFO:absl:Feature Hillshade_9am has no shape. Setting to VarLenSparseTensor.\n",
      "INFO:absl:Feature Hillshade_Noon has no shape. Setting to VarLenSparseTensor.\n",
      "INFO:absl:Feature Horizontal_Distance_To_Fire_Points has no shape. Setting to VarLenSparseTensor.\n",
      "INFO:absl:Feature Horizontal_Distance_To_Hydrology has no shape. Setting to VarLenSparseTensor.\n",
      "INFO:absl:Feature Horizontal_Distance_To_Roadways has no shape. Setting to VarLenSparseTensor.\n",
      "INFO:absl:Feature Slope has no shape. Setting to VarLenSparseTensor.\n",
      "INFO:absl:Feature Soil_Type has no shape. Setting to VarLenSparseTensor.\n",
      "INFO:absl:Feature Vertical_Distance_To_Hydrology has no shape. Setting to VarLenSparseTensor.\n",
      "INFO:absl:Feature Wilderness_Area has no shape. Setting to VarLenSparseTensor.\n",
      "INFO:absl:Feature Aspect has no shape. Setting to VarLenSparseTensor.\n",
      "INFO:absl:Feature Cover_Type has no shape. Setting to VarLenSparseTensor.\n",
      "INFO:absl:Feature Elevation has no shape. Setting to VarLenSparseTensor.\n",
      "INFO:absl:Feature Hillshade_3pm has no shape. Setting to VarLenSparseTensor.\n",
      "INFO:absl:Feature Hillshade_9am has no shape. Setting to VarLenSparseTensor.\n",
      "INFO:absl:Feature Hillshade_Noon has no shape. Setting to VarLenSparseTensor.\n",
      "INFO:absl:Feature Horizontal_Distance_To_Fire_Points has no shape. Setting to VarLenSparseTensor.\n",
      "INFO:absl:Feature Horizontal_Distance_To_Hydrology has no shape. Setting to VarLenSparseTensor.\n",
      "INFO:absl:Feature Horizontal_Distance_To_Roadways has no shape. Setting to VarLenSparseTensor.\n",
      "INFO:absl:Feature Slope has no shape. Setting to VarLenSparseTensor.\n",
      "INFO:absl:Feature Soil_Type has no shape. Setting to VarLenSparseTensor.\n",
      "INFO:absl:Feature Vertical_Distance_To_Hydrology has no shape. Setting to VarLenSparseTensor.\n",
      "INFO:absl:Feature Wilderness_Area has no shape. Setting to VarLenSparseTensor.\n",
      "INFO:absl:We decided to produce LargeList and LargeBinary types.\n",
      "INFO:absl:Feature Aspect has no shape. Setting to VarLenSparseTensor.\n",
      "INFO:absl:Feature Cover_Type has no shape. Setting to VarLenSparseTensor.\n",
      "INFO:absl:Feature Elevation has no shape. Setting to VarLenSparseTensor.\n",
      "INFO:absl:Feature Hillshade_3pm has no shape. Setting to VarLenSparseTensor.\n",
      "INFO:absl:Feature Hillshade_9am has no shape. Setting to VarLenSparseTensor.\n",
      "INFO:absl:Feature Hillshade_Noon has no shape. Setting to VarLenSparseTensor.\n",
      "INFO:absl:Feature Horizontal_Distance_To_Fire_Points has no shape. Setting to VarLenSparseTensor.\n",
      "INFO:absl:Feature Horizontal_Distance_To_Hydrology has no shape. Setting to VarLenSparseTensor.\n",
      "INFO:absl:Feature Horizontal_Distance_To_Roadways has no shape. Setting to VarLenSparseTensor.\n",
      "INFO:absl:Feature Slope has no shape. Setting to VarLenSparseTensor.\n",
      "INFO:absl:Feature Soil_Type has no shape. Setting to VarLenSparseTensor.\n",
      "INFO:absl:Feature Vertical_Distance_To_Hydrology has no shape. Setting to VarLenSparseTensor.\n",
      "INFO:absl:Feature Wilderness_Area has no shape. Setting to VarLenSparseTensor.\n",
      "INFO:absl:We decided to produce LargeList and LargeBinary types.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Tensorflow version (2.3.0) found. Note that Tensorflow Transform support for TF 2.0 is currently in beta, and features such as tf.function may not work as intended. \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:apache_beam.utils.interactive_utils:Failed to alter the label of a transform with the ipython prompt metadata. Cannot figure out the pipeline that the given pvalueish ({DatasetKey(key='end-to-end-CsvExampleGen.Data_Extraction_Spliting-examples-3-train-STAR'): <PCollection[TFXIOReadAndDecode[AnalysisIndex0]/RawRecordToRecordBatch/CollectRecordBatchTelemetry/ProfileRecordBatches.None] at 0x7fcf24e29f50>}, None, TensorAdapterConfig(arrow_schema=Aspect: large_list<item: int64>\n",
      "  child 0, item: int64\n",
      "Elevation: large_list<item: int64>\n",
      "  child 0, item: int64\n",
      "Hillshade_3pm: large_list<item: int64>\n",
      "  child 0, item: int64\n",
      "Hillshade_9am: large_list<item: int64>\n",
      "  child 0, item: int64\n",
      "Hillshade_Noon: large_list<item: int64>\n",
      "  child 0, item: int64\n",
      "Horizontal_Distance_To_Fire_Points: large_list<item: int64>\n",
      "  child 0, item: int64\n",
      "Horizontal_Distance_To_Hydrology: large_list<item: int64>\n",
      "  child 0, item: int64\n",
      "Horizontal_Distance_To_Roadways: large_list<item: int64>\n",
      "  child 0, item: int64\n",
      "Slope: large_list<item: int64>\n",
      "  child 0, item: int64\n",
      "Soil_Type: large_list<item: large_binary>\n",
      "  child 0, item: large_binary\n",
      "Vertical_Distance_To_Hydrology: large_list<item: int64>\n",
      "  child 0, item: int64\n",
      "Wilderness_Area: large_list<item: large_binary>\n",
      "  child 0, item: large_binary, tensor_representations={'Hillshade_9am': varlen_sparse_tensor {\n",
      "  column_name: \"Hillshade_9am\"\n",
      "}\n",
      ", 'Aspect': varlen_sparse_tensor {\n",
      "  column_name: \"Aspect\"\n",
      "}\n",
      ", 'Horizontal_Distance_To_Hydrology': varlen_sparse_tensor {\n",
      "  column_name: \"Horizontal_Distance_To_Hydrology\"\n",
      "}\n",
      ", 'Elevation': varlen_sparse_tensor {\n",
      "  column_name: \"Elevation\"\n",
      "}\n",
      ", 'Horizontal_Distance_To_Roadways': varlen_sparse_tensor {\n",
      "  column_name: \"Horizontal_Distance_To_Roadways\"\n",
      "}\n",
      ", 'Slope': varlen_sparse_tensor {\n",
      "  column_name: \"Slope\"\n",
      "}\n",
      ", 'Wilderness_Area': varlen_sparse_tensor {\n",
      "  column_name: \"Wilderness_Area\"\n",
      "}\n",
      ", 'Vertical_Distance_To_Hydrology': varlen_sparse_tensor {\n",
      "  column_name: \"Vertical_Distance_To_Hydrology\"\n",
      "}\n",
      ", 'Soil_Type': varlen_sparse_tensor {\n",
      "  column_name: \"Soil_Type\"\n",
      "}\n",
      ", 'Hillshade_3pm': varlen_sparse_tensor {\n",
      "  column_name: \"Hillshade_3pm\"\n",
      "}\n",
      ", 'Hillshade_Noon': varlen_sparse_tensor {\n",
      "  column_name: \"Hillshade_Noon\"\n",
      "}\n",
      ", 'Horizontal_Distance_To_Fire_Points': varlen_sparse_tensor {\n",
      "  column_name: \"Horizontal_Distance_To_Fire_Points\"\n",
      "}\n",
      "}, original_type_specs={'Aspect': SparseTensorSpec(TensorShape([None, None]), tf.int64), 'Cover_Type': SparseTensorSpec(TensorShape([None, None]), tf.int64), 'Elevation': SparseTensorSpec(TensorShape([None, None]), tf.int64), 'Hillshade_3pm': SparseTensorSpec(TensorShape([None, None]), tf.int64), 'Hillshade_9am': SparseTensorSpec(TensorShape([None, None]), tf.int64), 'Hillshade_Noon': SparseTensorSpec(TensorShape([None, None]), tf.int64), 'Horizontal_Distance_To_Fire_Points': SparseTensorSpec(TensorShape([None, None]), tf.int64), 'Horizontal_Distance_To_Hydrology': SparseTensorSpec(TensorShape([None, None]), tf.int64), 'Horizontal_Distance_To_Roadways': SparseTensorSpec(TensorShape([None, None]), tf.int64), 'Slope': SparseTensorSpec(TensorShape([None, None]), tf.int64), 'Soil_Type': SparseTensorSpec(TensorShape([None, None]), tf.string), 'Vertical_Distance_To_Hydrology': SparseTensorSpec(TensorShape([None, None]), tf.int64), 'Wilderness_Area': SparseTensorSpec(TensorShape([None, None]), tf.string)})) belongs to. Thus noop.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/tensorflow/python/saved_model/signature_def_utils_impl.py:201: build_tensor_info (from tensorflow.python.saved_model.utils_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.utils.build_tensor_info or tf.compat.v1.saved_model.build_tensor_info.\n",
      "INFO:tensorflow:Assets added to graph.\n",
      "INFO:tensorflow:No assets to write.\n",
      "WARNING:tensorflow:Issue encountered when serializing tft_mapper_use.\n",
      "Type is unsupported, or the types of the items don't match field type in CollectionDef. Note this is a warning and probably safe to ignore.\n",
      "'Counter' object has no attribute 'name'\n",
      "INFO:tensorflow:SavedModel written to: /home/jupyter/pipeline-root/end-to-end/Transform/transform_graph/6/.temp_path/tftransform_tmp/693728fe193f4a549f21fdebc416f335/saved_model.pb\n",
      "INFO:tensorflow:Assets added to graph.\n",
      "INFO:tensorflow:No assets to write.\n",
      "WARNING:tensorflow:Issue encountered when serializing tft_mapper_use.\n",
      "Type is unsupported, or the types of the items don't match field type in CollectionDef. Note this is a warning and probably safe to ignore.\n",
      "'Counter' object has no attribute 'name'\n",
      "INFO:tensorflow:SavedModel written to: /home/jupyter/pipeline-root/end-to-end/Transform/transform_graph/6/.temp_path/tftransform_tmp/4b19259143c744ecb68627878537a1ef/saved_model.pb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:apache_beam.utils.interactive_utils:Failed to alter the label of a transform with the ipython prompt metadata. Cannot figure out the pipeline that the given pvalueish {'_schema': feature {\n",
      "  name: \"Aspect\"\n",
      "  value_count {\n",
      "    min: 1\n",
      "    max: 1\n",
      "  }\n",
      "  type: INT\n",
      "  presence {\n",
      "    min_fraction: 1.0\n",
      "    min_count: 1\n",
      "  }\n",
      "}\n",
      "feature {\n",
      "  name: \"Cover_Type\"\n",
      "  value_count {\n",
      "    min: 1\n",
      "    max: 1\n",
      "  }\n",
      "  type: INT\n",
      "  presence {\n",
      "    min_fraction: 1.0\n",
      "    min_count: 1\n",
      "  }\n",
      "}\n",
      "feature {\n",
      "  name: \"Elevation\"\n",
      "  value_count {\n",
      "    min: 1\n",
      "    max: 1\n",
      "  }\n",
      "  type: INT\n",
      "  presence {\n",
      "    min_fraction: 1.0\n",
      "    min_count: 1\n",
      "  }\n",
      "}\n",
      "feature {\n",
      "  name: \"Hillshade_3pm\"\n",
      "  value_count {\n",
      "    min: 1\n",
      "    max: 1\n",
      "  }\n",
      "  type: INT\n",
      "  presence {\n",
      "    min_fraction: 1.0\n",
      "    min_count: 1\n",
      "  }\n",
      "}\n",
      "feature {\n",
      "  name: \"Hillshade_9am\"\n",
      "  value_count {\n",
      "    min: 1\n",
      "    max: 1\n",
      "  }\n",
      "  type: INT\n",
      "  presence {\n",
      "    min_fraction: 1.0\n",
      "    min_count: 1\n",
      "  }\n",
      "}\n",
      "feature {\n",
      "  name: \"Hillshade_Noon\"\n",
      "  value_count {\n",
      "    min: 1\n",
      "    max: 1\n",
      "  }\n",
      "  type: INT\n",
      "  presence {\n",
      "    min_fraction: 1.0\n",
      "    min_count: 1\n",
      "  }\n",
      "}\n",
      "feature {\n",
      "  name: \"Horizontal_Distance_To_Fire_Points\"\n",
      "  value_count {\n",
      "    min: 1\n",
      "    max: 1\n",
      "  }\n",
      "  type: INT\n",
      "  presence {\n",
      "    min_fraction: 1.0\n",
      "    min_count: 1\n",
      "  }\n",
      "}\n",
      "feature {\n",
      "  name: \"Horizontal_Distance_To_Hydrology\"\n",
      "  value_count {\n",
      "    min: 1\n",
      "    max: 1\n",
      "  }\n",
      "  type: INT\n",
      "  presence {\n",
      "    min_fraction: 1.0\n",
      "    min_count: 1\n",
      "  }\n",
      "}\n",
      "feature {\n",
      "  name: \"Horizontal_Distance_To_Roadways\"\n",
      "  value_count {\n",
      "    min: 1\n",
      "    max: 1\n",
      "  }\n",
      "  type: INT\n",
      "  presence {\n",
      "    min_fraction: 1.0\n",
      "    min_count: 1\n",
      "  }\n",
      "}\n",
      "feature {\n",
      "  name: \"Slope\"\n",
      "  value_count {\n",
      "    min: 1\n",
      "    max: 1\n",
      "  }\n",
      "  type: INT\n",
      "  presence {\n",
      "    min_fraction: 1.0\n",
      "    min_count: 1\n",
      "  }\n",
      "}\n",
      "feature {\n",
      "  name: \"Soil_Type\"\n",
      "  value_count {\n",
      "    min: 1\n",
      "    max: 1\n",
      "  }\n",
      "  type: BYTES\n",
      "  domain: \"Soil_Type\"\n",
      "  presence {\n",
      "    min_fraction: 1.0\n",
      "    min_count: 1\n",
      "  }\n",
      "}\n",
      "feature {\n",
      "  name: \"Vertical_Distance_To_Hydrology\"\n",
      "  value_count {\n",
      "    min: 1\n",
      "    max: 1\n",
      "  }\n",
      "  type: INT\n",
      "  presence {\n",
      "    min_fraction: 1.0\n",
      "    min_count: 1\n",
      "  }\n",
      "}\n",
      "feature {\n",
      "  name: \"Wilderness_Area\"\n",
      "  value_count {\n",
      "    min: 1\n",
      "    max: 1\n",
      "  }\n",
      "  type: BYTES\n",
      "  domain: \"Wilderness_Area\"\n",
      "  presence {\n",
      "    min_fraction: 1.0\n",
      "    min_count: 1\n",
      "  }\n",
      "}\n",
      "string_domain {\n",
      "  name: \"Soil_Type\"\n",
      "  value: \"C2702\"\n",
      "  value: \"C2703\"\n",
      "  value: \"C2704\"\n",
      "  value: \"C2705\"\n",
      "  value: \"C2706\"\n",
      "  value: \"C2717\"\n",
      "  value: \"C3501\"\n",
      "  value: \"C3502\"\n",
      "  value: \"C4201\"\n",
      "  value: \"C4703\"\n",
      "  value: \"C4704\"\n",
      "  value: \"C4744\"\n",
      "  value: \"C4758\"\n",
      "  value: \"C5101\"\n",
      "  value: \"C5151\"\n",
      "  value: \"C6101\"\n",
      "  value: \"C6102\"\n",
      "  value: \"C6731\"\n",
      "  value: \"C7101\"\n",
      "  value: \"C7102\"\n",
      "  value: \"C7103\"\n",
      "  value: \"C7201\"\n",
      "  value: \"C7202\"\n",
      "  value: \"C7700\"\n",
      "  value: \"C7701\"\n",
      "  value: \"C7702\"\n",
      "  value: \"C7709\"\n",
      "  value: \"C7710\"\n",
      "  value: \"C7745\"\n",
      "  value: \"C7746\"\n",
      "  value: \"C7755\"\n",
      "  value: \"C7756\"\n",
      "  value: \"C7757\"\n",
      "  value: \"C7790\"\n",
      "  value: \"C8703\"\n",
      "  value: \"C8707\"\n",
      "  value: \"C8708\"\n",
      "  value: \"C8771\"\n",
      "  value: \"C8772\"\n",
      "  value: \"C8776\"\n",
      "}\n",
      "string_domain {\n",
      "  name: \"Wilderness_Area\"\n",
      "  value: \"Cache\"\n",
      "  value: \"Commanche\"\n",
      "  value: \"Neota\"\n",
      "  value: \"Rawah\"\n",
      "}\n",
      "} belongs to. Thus noop.\n",
      "INFO:absl:Feature Aspect has no shape. Setting to VarLenSparseTensor.\n",
      "INFO:absl:Feature Cover_Type has no shape. Setting to VarLenSparseTensor.\n",
      "INFO:absl:Feature Elevation has no shape. Setting to VarLenSparseTensor.\n",
      "INFO:absl:Feature Hillshade_3pm has no shape. Setting to VarLenSparseTensor.\n",
      "INFO:absl:Feature Hillshade_9am has no shape. Setting to VarLenSparseTensor.\n",
      "INFO:absl:Feature Hillshade_Noon has no shape. Setting to VarLenSparseTensor.\n",
      "INFO:absl:Feature Horizontal_Distance_To_Fire_Points has no shape. Setting to VarLenSparseTensor.\n",
      "INFO:absl:Feature Horizontal_Distance_To_Hydrology has no shape. Setting to VarLenSparseTensor.\n",
      "INFO:absl:Feature Horizontal_Distance_To_Roadways has no shape. Setting to VarLenSparseTensor.\n",
      "INFO:absl:Feature Slope has no shape. Setting to VarLenSparseTensor.\n",
      "INFO:absl:Feature Soil_Type has no shape. Setting to VarLenSparseTensor.\n",
      "INFO:absl:Feature Vertical_Distance_To_Hydrology has no shape. Setting to VarLenSparseTensor.\n",
      "INFO:absl:Feature Wilderness_Area has no shape. Setting to VarLenSparseTensor.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Tensorflow version (2.3.0) found. Note that Tensorflow Transform support for TF 2.0 is currently in beta, and features such as tf.function may not work as intended. \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:apache_beam.utils.interactive_utils:Failed to alter the label of a transform with the ipython prompt metadata. Cannot figure out the pipeline that the given pvalueish ((<PCollection[TFXIOReadAndDecode[TransformIndex0]/RawRecordToRecordBatch/CollectRecordBatchTelemetry/ProfileRecordBatches.None] at 0x7fceee6d8410>, TensorAdapterConfig(arrow_schema=Aspect: large_list<item: int64>\n",
      "  child 0, item: int64\n",
      "Cover_Type: large_list<item: int64>\n",
      "  child 0, item: int64\n",
      "Elevation: large_list<item: int64>\n",
      "  child 0, item: int64\n",
      "Hillshade_3pm: large_list<item: int64>\n",
      "  child 0, item: int64\n",
      "Hillshade_9am: large_list<item: int64>\n",
      "  child 0, item: int64\n",
      "Hillshade_Noon: large_list<item: int64>\n",
      "  child 0, item: int64\n",
      "Horizontal_Distance_To_Fire_Points: large_list<item: int64>\n",
      "  child 0, item: int64\n",
      "Horizontal_Distance_To_Hydrology: large_list<item: int64>\n",
      "  child 0, item: int64\n",
      "Horizontal_Distance_To_Roadways: large_list<item: int64>\n",
      "  child 0, item: int64\n",
      "Slope: large_list<item: int64>\n",
      "  child 0, item: int64\n",
      "Soil_Type: large_list<item: large_binary>\n",
      "  child 0, item: large_binary\n",
      "Vertical_Distance_To_Hydrology: large_list<item: int64>\n",
      "  child 0, item: int64\n",
      "Wilderness_Area: large_list<item: large_binary>\n",
      "  child 0, item: large_binary, tensor_representations={'Wilderness_Area': varlen_sparse_tensor {\n",
      "  column_name: \"Wilderness_Area\"\n",
      "}\n",
      ", 'Vertical_Distance_To_Hydrology': varlen_sparse_tensor {\n",
      "  column_name: \"Vertical_Distance_To_Hydrology\"\n",
      "}\n",
      ", 'Cover_Type': varlen_sparse_tensor {\n",
      "  column_name: \"Cover_Type\"\n",
      "}\n",
      ", 'Soil_Type': varlen_sparse_tensor {\n",
      "  column_name: \"Soil_Type\"\n",
      "}\n",
      ", 'Hillshade_3pm': varlen_sparse_tensor {\n",
      "  column_name: \"Hillshade_3pm\"\n",
      "}\n",
      ", 'Hillshade_Noon': varlen_sparse_tensor {\n",
      "  column_name: \"Hillshade_Noon\"\n",
      "}\n",
      ", 'Horizontal_Distance_To_Fire_Points': varlen_sparse_tensor {\n",
      "  column_name: \"Horizontal_Distance_To_Fire_Points\"\n",
      "}\n",
      ", 'Hillshade_9am': varlen_sparse_tensor {\n",
      "  column_name: \"Hillshade_9am\"\n",
      "}\n",
      ", 'Aspect': varlen_sparse_tensor {\n",
      "  column_name: \"Aspect\"\n",
      "}\n",
      ", 'Horizontal_Distance_To_Hydrology': varlen_sparse_tensor {\n",
      "  column_name: \"Horizontal_Distance_To_Hydrology\"\n",
      "}\n",
      ", 'Elevation': varlen_sparse_tensor {\n",
      "  column_name: \"Elevation\"\n",
      "}\n",
      ", 'Horizontal_Distance_To_Roadways': varlen_sparse_tensor {\n",
      "  column_name: \"Horizontal_Distance_To_Roadways\"\n",
      "}\n",
      ", 'Slope': varlen_sparse_tensor {\n",
      "  column_name: \"Slope\"\n",
      "}\n",
      "}, original_type_specs={'Aspect': SparseTensorSpec(TensorShape([None, None]), tf.int64), 'Cover_Type': SparseTensorSpec(TensorShape([None, None]), tf.int64), 'Elevation': SparseTensorSpec(TensorShape([None, None]), tf.int64), 'Hillshade_3pm': SparseTensorSpec(TensorShape([None, None]), tf.int64), 'Hillshade_9am': SparseTensorSpec(TensorShape([None, None]), tf.int64), 'Hillshade_Noon': SparseTensorSpec(TensorShape([None, None]), tf.int64), 'Horizontal_Distance_To_Fire_Points': SparseTensorSpec(TensorShape([None, None]), tf.int64), 'Horizontal_Distance_To_Hydrology': SparseTensorSpec(TensorShape([None, None]), tf.int64), 'Horizontal_Distance_To_Roadways': SparseTensorSpec(TensorShape([None, None]), tf.int64), 'Slope': SparseTensorSpec(TensorShape([None, None]), tf.int64), 'Soil_Type': SparseTensorSpec(TensorShape([None, None]), tf.string), 'Vertical_Distance_To_Hydrology': SparseTensorSpec(TensorShape([None, None]), tf.int64), 'Wilderness_Area': SparseTensorSpec(TensorShape([None, None]), tf.string)})), (<PCollection[Analyze/CreateSavedModel/BindTensors/ReplaceWithConstants.None] at 0x7fceee7dc050>, BeamDatasetMetadata(dataset_metadata={'_schema': feature {\n",
      "  name: \"Aspect_xf\"\n",
      "  type: FLOAT\n",
      "  presence {\n",
      "    min_fraction: 1.0\n",
      "  }\n",
      "  shape {\n",
      "  }\n",
      "}\n",
      "feature {\n",
      "  name: \"Cover_Type_xf\"\n",
      "  type: INT\n",
      "  presence {\n",
      "    min_fraction: 1.0\n",
      "  }\n",
      "  shape {\n",
      "  }\n",
      "}\n",
      "feature {\n",
      "  name: \"Elevation_xf\"\n",
      "  type: FLOAT\n",
      "  presence {\n",
      "    min_fraction: 1.0\n",
      "  }\n",
      "  shape {\n",
      "  }\n",
      "}\n",
      "feature {\n",
      "  name: \"Hillshade_3pm_xf\"\n",
      "  type: FLOAT\n",
      "  presence {\n",
      "    min_fraction: 1.0\n",
      "  }\n",
      "  shape {\n",
      "  }\n",
      "}\n",
      "feature {\n",
      "  name: \"Hillshade_9am_xf\"\n",
      "  type: FLOAT\n",
      "  presence {\n",
      "    min_fraction: 1.0\n",
      "  }\n",
      "  shape {\n",
      "  }\n",
      "}\n",
      "feature {\n",
      "  name: \"Hillshade_Noon_xf\"\n",
      "  type: FLOAT\n",
      "  presence {\n",
      "    min_fraction: 1.0\n",
      "  }\n",
      "  shape {\n",
      "  }\n",
      "}\n",
      "feature {\n",
      "  name: \"Horizontal_Distance_To_Fire_Points_xf\"\n",
      "  type: FLOAT\n",
      "  presence {\n",
      "    min_fraction: 1.0\n",
      "  }\n",
      "  shape {\n",
      "  }\n",
      "}\n",
      "feature {\n",
      "  name: \"Horizontal_Distance_To_Hydrology_xf\"\n",
      "  type: FLOAT\n",
      "  presence {\n",
      "    min_fraction: 1.0\n",
      "  }\n",
      "  shape {\n",
      "  }\n",
      "}\n",
      "feature {\n",
      "  name: \"Horizontal_Distance_To_Roadways_xf\"\n",
      "  type: FLOAT\n",
      "  presence {\n",
      "    min_fraction: 1.0\n",
      "  }\n",
      "  shape {\n",
      "  }\n",
      "}\n",
      "feature {\n",
      "  name: \"Slope_xf\"\n",
      "  type: FLOAT\n",
      "  presence {\n",
      "    min_fraction: 1.0\n",
      "  }\n",
      "  shape {\n",
      "  }\n",
      "}\n",
      "feature {\n",
      "  name: \"Soil_Type_xf\"\n",
      "  type: INT\n",
      "  int_domain {\n",
      "    is_categorical: true\n",
      "  }\n",
      "  presence {\n",
      "    min_fraction: 1.0\n",
      "  }\n",
      "  shape {\n",
      "  }\n",
      "}\n",
      "feature {\n",
      "  name: \"Vertical_Distance_To_Hydrology_xf\"\n",
      "  type: FLOAT\n",
      "  presence {\n",
      "    min_fraction: 1.0\n",
      "  }\n",
      "  shape {\n",
      "  }\n",
      "}\n",
      "feature {\n",
      "  name: \"Wilderness_Area_xf\"\n",
      "  type: INT\n",
      "  int_domain {\n",
      "    is_categorical: true\n",
      "  }\n",
      "  presence {\n",
      "    min_fraction: 1.0\n",
      "  }\n",
      "  shape {\n",
      "  }\n",
      "}\n",
      "}, deferred_metadata=<PCollection[Analyze/ComputeDeferredMetadata.None] at 0x7fceee6f4690>))) belongs to. Thus noop.\n",
      "WARNING:apache_beam.typehints.typehints:Ignoring send_type hint: <class 'NoneType'>\n",
      "WARNING:apache_beam.typehints.typehints:Ignoring return_type hint: <class 'NoneType'>\n",
      "WARNING:apache_beam.typehints.typehints:Ignoring send_type hint: <class 'NoneType'>\n",
      "WARNING:apache_beam.typehints.typehints:Ignoring return_type hint: <class 'NoneType'>\n",
      "WARNING:apache_beam.typehints.typehints:Ignoring send_type hint: <class 'NoneType'>\n",
      "WARNING:apache_beam.typehints.typehints:Ignoring return_type hint: <class 'NoneType'>\n",
      "INFO:absl:Feature Aspect has no shape. Setting to VarLenSparseTensor.\n",
      "INFO:absl:Feature Cover_Type has no shape. Setting to VarLenSparseTensor.\n",
      "INFO:absl:Feature Elevation has no shape. Setting to VarLenSparseTensor.\n",
      "INFO:absl:Feature Hillshade_3pm has no shape. Setting to VarLenSparseTensor.\n",
      "INFO:absl:Feature Hillshade_9am has no shape. Setting to VarLenSparseTensor.\n",
      "INFO:absl:Feature Hillshade_Noon has no shape. Setting to VarLenSparseTensor.\n",
      "INFO:absl:Feature Horizontal_Distance_To_Fire_Points has no shape. Setting to VarLenSparseTensor.\n",
      "INFO:absl:Feature Horizontal_Distance_To_Hydrology has no shape. Setting to VarLenSparseTensor.\n",
      "INFO:absl:Feature Horizontal_Distance_To_Roadways has no shape. Setting to VarLenSparseTensor.\n",
      "INFO:absl:Feature Slope has no shape. Setting to VarLenSparseTensor.\n",
      "INFO:absl:Feature Soil_Type has no shape. Setting to VarLenSparseTensor.\n",
      "INFO:absl:Feature Vertical_Distance_To_Hydrology has no shape. Setting to VarLenSparseTensor.\n",
      "INFO:absl:Feature Wilderness_Area has no shape. Setting to VarLenSparseTensor.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Tensorflow version (2.3.0) found. Note that Tensorflow Transform support for TF 2.0 is currently in beta, and features such as tf.function may not work as intended. \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:apache_beam.utils.interactive_utils:Failed to alter the label of a transform with the ipython prompt metadata. Cannot figure out the pipeline that the given pvalueish ((<PCollection[TFXIOReadAndDecode[TransformIndex1]/RawRecordToRecordBatch/CollectRecordBatchTelemetry/ProfileRecordBatches.None] at 0x7fceee6f4850>, TensorAdapterConfig(arrow_schema=Aspect: large_list<item: int64>\n",
      "  child 0, item: int64\n",
      "Cover_Type: large_list<item: int64>\n",
      "  child 0, item: int64\n",
      "Elevation: large_list<item: int64>\n",
      "  child 0, item: int64\n",
      "Hillshade_3pm: large_list<item: int64>\n",
      "  child 0, item: int64\n",
      "Hillshade_9am: large_list<item: int64>\n",
      "  child 0, item: int64\n",
      "Hillshade_Noon: large_list<item: int64>\n",
      "  child 0, item: int64\n",
      "Horizontal_Distance_To_Fire_Points: large_list<item: int64>\n",
      "  child 0, item: int64\n",
      "Horizontal_Distance_To_Hydrology: large_list<item: int64>\n",
      "  child 0, item: int64\n",
      "Horizontal_Distance_To_Roadways: large_list<item: int64>\n",
      "  child 0, item: int64\n",
      "Slope: large_list<item: int64>\n",
      "  child 0, item: int64\n",
      "Soil_Type: large_list<item: large_binary>\n",
      "  child 0, item: large_binary\n",
      "Vertical_Distance_To_Hydrology: large_list<item: int64>\n",
      "  child 0, item: int64\n",
      "Wilderness_Area: large_list<item: large_binary>\n",
      "  child 0, item: large_binary, tensor_representations={'Cover_Type': varlen_sparse_tensor {\n",
      "  column_name: \"Cover_Type\"\n",
      "}\n",
      ", 'Soil_Type': varlen_sparse_tensor {\n",
      "  column_name: \"Soil_Type\"\n",
      "}\n",
      ", 'Hillshade_3pm': varlen_sparse_tensor {\n",
      "  column_name: \"Hillshade_3pm\"\n",
      "}\n",
      ", 'Hillshade_Noon': varlen_sparse_tensor {\n",
      "  column_name: \"Hillshade_Noon\"\n",
      "}\n",
      ", 'Horizontal_Distance_To_Fire_Points': varlen_sparse_tensor {\n",
      "  column_name: \"Horizontal_Distance_To_Fire_Points\"\n",
      "}\n",
      ", 'Hillshade_9am': varlen_sparse_tensor {\n",
      "  column_name: \"Hillshade_9am\"\n",
      "}\n",
      ", 'Aspect': varlen_sparse_tensor {\n",
      "  column_name: \"Aspect\"\n",
      "}\n",
      ", 'Horizontal_Distance_To_Hydrology': varlen_sparse_tensor {\n",
      "  column_name: \"Horizontal_Distance_To_Hydrology\"\n",
      "}\n",
      ", 'Elevation': varlen_sparse_tensor {\n",
      "  column_name: \"Elevation\"\n",
      "}\n",
      ", 'Horizontal_Distance_To_Roadways': varlen_sparse_tensor {\n",
      "  column_name: \"Horizontal_Distance_To_Roadways\"\n",
      "}\n",
      ", 'Slope': varlen_sparse_tensor {\n",
      "  column_name: \"Slope\"\n",
      "}\n",
      ", 'Wilderness_Area': varlen_sparse_tensor {\n",
      "  column_name: \"Wilderness_Area\"\n",
      "}\n",
      ", 'Vertical_Distance_To_Hydrology': varlen_sparse_tensor {\n",
      "  column_name: \"Vertical_Distance_To_Hydrology\"\n",
      "}\n",
      "}, original_type_specs={'Aspect': SparseTensorSpec(TensorShape([None, None]), tf.int64), 'Cover_Type': SparseTensorSpec(TensorShape([None, None]), tf.int64), 'Elevation': SparseTensorSpec(TensorShape([None, None]), tf.int64), 'Hillshade_3pm': SparseTensorSpec(TensorShape([None, None]), tf.int64), 'Hillshade_9am': SparseTensorSpec(TensorShape([None, None]), tf.int64), 'Hillshade_Noon': SparseTensorSpec(TensorShape([None, None]), tf.int64), 'Horizontal_Distance_To_Fire_Points': SparseTensorSpec(TensorShape([None, None]), tf.int64), 'Horizontal_Distance_To_Hydrology': SparseTensorSpec(TensorShape([None, None]), tf.int64), 'Horizontal_Distance_To_Roadways': SparseTensorSpec(TensorShape([None, None]), tf.int64), 'Slope': SparseTensorSpec(TensorShape([None, None]), tf.int64), 'Soil_Type': SparseTensorSpec(TensorShape([None, None]), tf.string), 'Vertical_Distance_To_Hydrology': SparseTensorSpec(TensorShape([None, None]), tf.int64), 'Wilderness_Area': SparseTensorSpec(TensorShape([None, None]), tf.string)})), (<PCollection[Analyze/CreateSavedModel/BindTensors/ReplaceWithConstants.None] at 0x7fceee7dc050>, BeamDatasetMetadata(dataset_metadata={'_schema': feature {\n",
      "  name: \"Aspect_xf\"\n",
      "  type: FLOAT\n",
      "  presence {\n",
      "    min_fraction: 1.0\n",
      "  }\n",
      "  shape {\n",
      "  }\n",
      "}\n",
      "feature {\n",
      "  name: \"Cover_Type_xf\"\n",
      "  type: INT\n",
      "  presence {\n",
      "    min_fraction: 1.0\n",
      "  }\n",
      "  shape {\n",
      "  }\n",
      "}\n",
      "feature {\n",
      "  name: \"Elevation_xf\"\n",
      "  type: FLOAT\n",
      "  presence {\n",
      "    min_fraction: 1.0\n",
      "  }\n",
      "  shape {\n",
      "  }\n",
      "}\n",
      "feature {\n",
      "  name: \"Hillshade_3pm_xf\"\n",
      "  type: FLOAT\n",
      "  presence {\n",
      "    min_fraction: 1.0\n",
      "  }\n",
      "  shape {\n",
      "  }\n",
      "}\n",
      "feature {\n",
      "  name: \"Hillshade_9am_xf\"\n",
      "  type: FLOAT\n",
      "  presence {\n",
      "    min_fraction: 1.0\n",
      "  }\n",
      "  shape {\n",
      "  }\n",
      "}\n",
      "feature {\n",
      "  name: \"Hillshade_Noon_xf\"\n",
      "  type: FLOAT\n",
      "  presence {\n",
      "    min_fraction: 1.0\n",
      "  }\n",
      "  shape {\n",
      "  }\n",
      "}\n",
      "feature {\n",
      "  name: \"Horizontal_Distance_To_Fire_Points_xf\"\n",
      "  type: FLOAT\n",
      "  presence {\n",
      "    min_fraction: 1.0\n",
      "  }\n",
      "  shape {\n",
      "  }\n",
      "}\n",
      "feature {\n",
      "  name: \"Horizontal_Distance_To_Hydrology_xf\"\n",
      "  type: FLOAT\n",
      "  presence {\n",
      "    min_fraction: 1.0\n",
      "  }\n",
      "  shape {\n",
      "  }\n",
      "}\n",
      "feature {\n",
      "  name: \"Horizontal_Distance_To_Roadways_xf\"\n",
      "  type: FLOAT\n",
      "  presence {\n",
      "    min_fraction: 1.0\n",
      "  }\n",
      "  shape {\n",
      "  }\n",
      "}\n",
      "feature {\n",
      "  name: \"Slope_xf\"\n",
      "  type: FLOAT\n",
      "  presence {\n",
      "    min_fraction: 1.0\n",
      "  }\n",
      "  shape {\n",
      "  }\n",
      "}\n",
      "feature {\n",
      "  name: \"Soil_Type_xf\"\n",
      "  type: INT\n",
      "  int_domain {\n",
      "    is_categorical: true\n",
      "  }\n",
      "  presence {\n",
      "    min_fraction: 1.0\n",
      "  }\n",
      "  shape {\n",
      "  }\n",
      "}\n",
      "feature {\n",
      "  name: \"Vertical_Distance_To_Hydrology_xf\"\n",
      "  type: FLOAT\n",
      "  presence {\n",
      "    min_fraction: 1.0\n",
      "  }\n",
      "  shape {\n",
      "  }\n",
      "}\n",
      "feature {\n",
      "  name: \"Wilderness_Area_xf\"\n",
      "  type: INT\n",
      "  int_domain {\n",
      "    is_categorical: true\n",
      "  }\n",
      "  presence {\n",
      "    min_fraction: 1.0\n",
      "  }\n",
      "  shape {\n",
      "  }\n",
      "}\n",
      "}, deferred_metadata=<PCollection[Analyze/ComputeDeferredMetadata.None] at 0x7fceee6f4690>))) belongs to. Thus noop.\n",
      "WARNING:apache_beam.typehints.typehints:Ignoring send_type hint: <class 'NoneType'>\n",
      "WARNING:apache_beam.typehints.typehints:Ignoring return_type hint: <class 'NoneType'>\n",
      "WARNING:apache_beam.typehints.typehints:Ignoring send_type hint: <class 'NoneType'>\n",
      "WARNING:apache_beam.typehints.typehints:Ignoring return_type hint: <class 'NoneType'>\n",
      "WARNING:apache_beam.typehints.typehints:Ignoring send_type hint: <class 'NoneType'>\n",
      "WARNING:apache_beam.typehints.typehints:Ignoring return_type hint: <class 'NoneType'>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n",
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n",
      "INFO:tensorflow:Assets added to graph.\n",
      "INFO:tensorflow:Assets written to: /home/jupyter/pipeline-root/end-to-end/Transform/transform_graph/6/.temp_path/tftransform_tmp/f7680f9aa7f946c596bd6c12a444590e/assets\n",
      "INFO:tensorflow:SavedModel written to: /home/jupyter/pipeline-root/end-to-end/Transform/transform_graph/6/.temp_path/tftransform_tmp/f7680f9aa7f946c596bd6c12a444590e/saved_model.pb\n",
      "WARNING:tensorflow:Expected binary or unicode string, got type_url: \"type.googleapis.com/tensorflow.AssetFileDef\"\n",
      "value: \"\\n\\013\\n\\tConst_3:0\\022\\017Wilderness_Area\"\n",
      "\n",
      "WARNING:tensorflow:Expected binary or unicode string, got type_url: \"type.googleapis.com/tensorflow.AssetFileDef\"\n",
      "value: \"\\n\\013\\n\\tConst_5:0\\022\\tSoil_Type\"\n",
      "\n",
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n",
      "WARNING:tensorflow:Expected binary or unicode string, got type_url: \"type.googleapis.com/tensorflow.AssetFileDef\"\n",
      "value: \"\\n\\013\\n\\tConst_3:0\\022\\017Wilderness_Area\"\n",
      "\n",
      "WARNING:tensorflow:Expected binary or unicode string, got type_url: \"type.googleapis.com/tensorflow.AssetFileDef\"\n",
      "value: \"\\n\\013\\n\\tConst_5:0\\022\\tSoil_Type\"\n",
      "\n",
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n",
      "WARNING:tensorflow:Expected binary or unicode string, got type_url: \"type.googleapis.com/tensorflow.AssetFileDef\"\n",
      "value: \"\\n\\013\\n\\tConst_3:0\\022\\017Wilderness_Area\"\n",
      "\n",
      "WARNING:tensorflow:Expected binary or unicode string, got type_url: \"type.googleapis.com/tensorflow.AssetFileDef\"\n",
      "value: \"\\n\\013\\n\\tConst_5:0\\022\\tSoil_Type\"\n",
      "\n",
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:absl:Running publisher for Transform\n",
      "INFO:absl:MetadataStore with DB connection initialized\n",
      "INFO:absl:Component Transform is finished.\n",
      "INFO:absl:Component Trainer is running.\n",
      "INFO:absl:Running driver for Trainer\n",
      "INFO:absl:MetadataStore with DB connection initialized\n",
      "INFO:absl:Running executor for Trainer\n",
      "INFO:absl:Train on the 'train' split when train_args.splits is not set.\n",
      "INFO:absl:Evaluate on the 'eval' split when eval_args.splits is not set.\n",
      "INFO:absl:Training model.\n",
      "INFO:absl:Model: \"functional_1\"\n",
      "INFO:absl:__________________________________________________________________________________________________\n",
      "INFO:absl:Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "INFO:absl:==================================================================================================\n",
      "INFO:absl:Aspect_xf (InputLayer)          [(None,)]            0                                            \n",
      "INFO:absl:__________________________________________________________________________________________________\n",
      "INFO:absl:Elevation_xf (InputLayer)       [(None,)]            0                                            \n",
      "INFO:absl:__________________________________________________________________________________________________\n",
      "INFO:absl:Hillshade_3pm_xf (InputLayer)   [(None,)]            0                                            \n",
      "INFO:absl:__________________________________________________________________________________________________\n",
      "INFO:absl:Hillshade_9am_xf (InputLayer)   [(None,)]            0                                            \n",
      "INFO:absl:__________________________________________________________________________________________________\n",
      "INFO:absl:Hillshade_Noon_xf (InputLayer)  [(None,)]            0                                            \n",
      "INFO:absl:__________________________________________________________________________________________________\n",
      "INFO:absl:Horizontal_Distance_To_Fire_Poi [(None,)]            0                                            \n",
      "INFO:absl:__________________________________________________________________________________________________\n",
      "INFO:absl:Horizontal_Distance_To_Hydrolog [(None,)]            0                                            \n",
      "INFO:absl:__________________________________________________________________________________________________\n",
      "INFO:absl:Horizontal_Distance_To_Roadways [(None,)]            0                                            \n",
      "INFO:absl:__________________________________________________________________________________________________\n",
      "INFO:absl:Slope_xf (InputLayer)           [(None,)]            0                                            \n",
      "INFO:absl:__________________________________________________________________________________________________\n",
      "INFO:absl:Soil_Type_xf (InputLayer)       [(None,)]            0                                            \n",
      "INFO:absl:__________________________________________________________________________________________________\n",
      "INFO:absl:Vertical_Distance_To_Hydrology_ [(None,)]            0                                            \n",
      "INFO:absl:__________________________________________________________________________________________________\n",
      "INFO:absl:Wilderness_Area_xf (InputLayer) [(None,)]            0                                            \n",
      "INFO:absl:__________________________________________________________________________________________________\n",
      "INFO:absl:dense_features (DenseFeatures)  (None, 10)           0           Aspect_xf[0][0]                  \n",
      "INFO:absl:                                                                 Elevation_xf[0][0]               \n",
      "INFO:absl:                                                                 Hillshade_3pm_xf[0][0]           \n",
      "INFO:absl:                                                                 Hillshade_9am_xf[0][0]           \n",
      "INFO:absl:                                                                 Hillshade_Noon_xf[0][0]          \n",
      "INFO:absl:                                                                 Horizontal_Distance_To_Fire_Point\n",
      "INFO:absl:                                                                 Horizontal_Distance_To_Hydrology_\n",
      "INFO:absl:                                                                 Horizontal_Distance_To_Roadways_x\n",
      "INFO:absl:                                                                 Slope_xf[0][0]                   \n",
      "INFO:absl:                                                                 Soil_Type_xf[0][0]               \n",
      "INFO:absl:                                                                 Vertical_Distance_To_Hydrology_xf\n",
      "INFO:absl:                                                                 Wilderness_Area_xf[0][0]         \n",
      "INFO:absl:__________________________________________________________________________________________________\n",
      "INFO:absl:dense (Dense)                   (None, 16)           176         dense_features[0][0]             \n",
      "INFO:absl:__________________________________________________________________________________________________\n",
      "INFO:absl:dense_1 (Dense)                 (None, 8)            136         dense[0][0]                      \n",
      "INFO:absl:__________________________________________________________________________________________________\n",
      "INFO:absl:dense_features_1 (DenseFeatures (None, 46)           0           Aspect_xf[0][0]                  \n",
      "INFO:absl:                                                                 Elevation_xf[0][0]               \n",
      "INFO:absl:                                                                 Hillshade_3pm_xf[0][0]           \n",
      "INFO:absl:                                                                 Hillshade_9am_xf[0][0]           \n",
      "INFO:absl:                                                                 Hillshade_Noon_xf[0][0]          \n",
      "INFO:absl:                                                                 Horizontal_Distance_To_Fire_Point\n",
      "INFO:absl:                                                                 Horizontal_Distance_To_Hydrology_\n",
      "INFO:absl:                                                                 Horizontal_Distance_To_Roadways_x\n",
      "INFO:absl:                                                                 Slope_xf[0][0]                   \n",
      "INFO:absl:                                                                 Soil_Type_xf[0][0]               \n",
      "INFO:absl:                                                                 Vertical_Distance_To_Hydrology_xf\n",
      "INFO:absl:                                                                 Wilderness_Area_xf[0][0]         \n",
      "INFO:absl:__________________________________________________________________________________________________\n",
      "INFO:absl:concatenate (Concatenate)       (None, 54)           0           dense_1[0][0]                    \n",
      "INFO:absl:                                                                 dense_features_1[0][0]           \n",
      "INFO:absl:__________________________________________________________________________________________________\n",
      "INFO:absl:dense_2 (Dense)                 (None, 7)            385         concatenate[0][0]                \n",
      "INFO:absl:==================================================================================================\n",
      "INFO:absl:Total params: 697\n",
      "INFO:absl:Trainable params: 697\n",
      "INFO:absl:Non-trainable params: 0\n",
      "INFO:absl:__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/tensorflow/python/ops/summary_ops_v2.py:1277: stop (from tensorflow.python.eager.profiler) is deprecated and will be removed after 2020-07-01.\n",
      "Instructions for updating:\n",
      "use `tf.profiler.experimental.stop` instead.\n",
      "WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0099s vs `on_train_batch_end` time: 0.0513s). Check your callbacks.\n",
      "5000/5000 - 26s - loss: 0.7024 - sparse_categorical_accuracy: 0.7044 - val_loss: 0.6453 - val_sparse_categorical_accuracy: 0.7202\n",
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "INFO:tensorflow:Assets written to: /home/jupyter/pipeline-root/end-to-end/Trainer/model/7/serving_model_dir/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:absl:Training complete. Model written to /home/jupyter/pipeline-root/end-to-end/Trainer/model/7/serving_model_dir. ModelRun written to /home/jupyter/pipeline-root/end-to-end/Trainer/model_run/7\n",
      "INFO:absl:Running publisher for Trainer\n",
      "INFO:absl:MetadataStore with DB connection initialized\n",
      "INFO:absl:Component Trainer is finished.\n",
      "INFO:absl:Component Evaluator is running.\n",
      "INFO:absl:Running driver for Evaluator\n",
      "INFO:absl:MetadataStore with DB connection initialized\n",
      "INFO:absl:Running executor for Evaluator\n",
      "INFO:absl:Request was made to ignore the baseline ModelSpec and any change thresholds. This is likely because a baseline model was not provided: updated_config=\n",
      "model_specs {\n",
      "  label_key: \"Cover_Type\"\n",
      "}\n",
      "slicing_specs {\n",
      "}\n",
      "slicing_specs {\n",
      "  feature_keys: \"Wilderness_Area\"\n",
      "}\n",
      "metrics_specs {\n",
      "  metrics {\n",
      "    class_name: \"SparseCategoricalAccuracy\"\n",
      "    threshold {\n",
      "      value_threshold {\n",
      "        lower_bound {\n",
      "          value: 0.5\n",
      "        }\n",
      "        upper_bound {\n",
      "          value: 0.99\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  metrics {\n",
      "    class_name: \"ExampleCount\"\n",
      "    threshold {\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "INFO:absl:Using /home/jupyter/pipeline-root/end-to-end/Trainer/model/7/serving_model_dir as  model.\n",
      "INFO:absl:The 'example_splits' parameter is not set, using 'eval' split.\n",
      "INFO:absl:Evaluating model.\n",
      "WARNING:absl:inputs do not match those expected by the model: input_names=['examples'], found in extracts={}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 5 calls to <function recreate_function.<locals>.restored_function_body at 0x7fcfa4a3bef0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:absl:Evaluation complete. Results written to /home/jupyter/pipeline-root/end-to-end/Evaluator/evaluation/8.\n",
      "INFO:absl:Checking validation results.\n",
      "INFO:absl:Blessing result True written to /home/jupyter/pipeline-root/end-to-end/Evaluator/blessing/8.\n",
      "INFO:absl:Running publisher for Evaluator\n",
      "INFO:absl:MetadataStore with DB connection initialized\n",
      "INFO:absl:Component Evaluator is finished.\n",
      "INFO:absl:Component InfraValidator is running.\n",
      "INFO:absl:Running driver for InfraValidator\n",
      "INFO:absl:MetadataStore with DB connection initialized\n",
      "INFO:absl:Running executor for InfraValidator\n",
      "INFO:absl:Unable to register signal handler for non-MainThread (name=Thread-8). SIGTERM will not be handled.\n",
      "INFO:absl:InfraValidator will be run in LOAD_AND_QUERY mode.\n",
      "INFO:absl:tag_set is not given. Using {'serve'} instead.\n",
      "INFO:absl:signature_names are not given. Using ['serving_default'] instead.\n",
      "INFO:absl:Creating temp directory at /home/jupyter/pipeline-root/end-to-end/.temp/9/\n",
      "INFO:absl:Starting infra validation (attempt 1/5).\n",
      "INFO:absl:Starting LocalDockerRunner(image: tensorflow/serving:latest).\n",
      "INFO:absl:Running container with parameter {'auto_remove': True, 'detach': True, 'publish_all_ports': True, 'image': 'tensorflow/serving:latest', 'environment': {'MODEL_NAME': 'infra-validation-model', 'MODEL_BASE_PATH': '/model'}, 'mounts': [{'Target': '/model/infra-validation-model/1', 'Source': '/home/jupyter/pipeline-root/end-to-end/.temp/9/infra-validation-model/1598733819', 'Type': 'bind', 'ReadOnly': True}]}\n",
      "INFO:absl:Error while obtaining model status:\n",
      "<_InactiveRpcError of RPC that terminated with:\n",
      "\tstatus = StatusCode.UNAVAILABLE\n",
      "\tdetails = \"Connection reset by peer\"\n",
      "\tdebug_error_string = \"{\"created\":\"@1598733820.389514812\",\"description\":\"Error received from peer ipv6:[::1]:32775\",\"file\":\"src/core/lib/surface/call.cc\",\"file_line\":1062,\"grpc_message\":\"Connection reset by peer\",\"grpc_status\":14}\"\n",
      ">\n",
      "INFO:absl:Waiting for model to be loaded...\n",
      "INFO:absl:Model is successfully loaded.\n",
      "INFO:absl:Stopping LocalDockerRunner(image: tensorflow/serving:latest).\n",
      "INFO:absl:Stopping container.\n",
      "INFO:absl:Model passed infra validation.\n",
      "INFO:absl:Running publisher for InfraValidator\n",
      "INFO:absl:MetadataStore with DB connection initialized\n",
      "INFO:absl:Component InfraValidator is finished.\n",
      "INFO:absl:Component ExampleValidator.Data_Validation is running.\n",
      "INFO:absl:Running driver for ExampleValidator.Data_Validation\n",
      "INFO:absl:MetadataStore with DB connection initialized\n",
      "INFO:absl:Running executor for ExampleValidator.Data_Validation\n",
      "INFO:absl:Validating schema against the computed statistics for split train.\n",
      "INFO:absl:Validation complete for split train. Anomalies written to /home/jupyter/pipeline-root/end-to-end/ExampleValidator.Data_Validation/anomalies/10/train.\n",
      "INFO:absl:Validating schema against the computed statistics for split eval.\n",
      "INFO:absl:Validation complete for split eval. Anomalies written to /home/jupyter/pipeline-root/end-to-end/ExampleValidator.Data_Validation/anomalies/10/eval.\n",
      "INFO:absl:Running publisher for ExampleValidator.Data_Validation\n",
      "INFO:absl:MetadataStore with DB connection initialized\n",
      "INFO:absl:Component ExampleValidator.Data_Validation is finished.\n",
      "INFO:absl:Component Pusher is running.\n",
      "INFO:absl:Running driver for Pusher\n",
      "INFO:absl:MetadataStore with DB connection initialized\n",
      "INFO:absl:Running executor for Pusher\n",
      "INFO:absl:Model version: 1598733832\n",
      "INFO:absl:Model written to serving path /home/jupyter/serving_model/1598733832.\n",
      "INFO:absl:Model pushed to /home/jupyter/pipeline-root/end-to-end/Pusher/pushed_model/11.\n",
      "INFO:absl:Running publisher for Pusher\n",
      "INFO:absl:MetadataStore with DB connection initialized\n",
      "INFO:absl:Component Pusher is finished.\n"
     ]
    }
   ],
   "source": [
    "BeamDagRunner().run(pipeline)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examine the artifacts created by the pipeline run\n",
    "\n",
    "#### Visualize statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:absl:MetadataStore with DB connection initialized\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<iframe id='facets-iframe' width=\"100%\" height=\"500px\"></iframe>\n",
       "        <script>\n",
       "        facets_iframe = document.getElementById('facets-iframe');\n",
       "        facets_html = '<script src=\"https://cdnjs.cloudflare.com/ajax/libs/webcomponentsjs/1.3.3/webcomponents-lite.js\"><\\/script><link rel=\"import\" href=\"https://raw.githubusercontent.com/PAIR-code/facets/master/facets-dist/facets-jupyter.html\"><facets-overview proto-input=\"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\"></facets-overview>';\n",
       "        facets_iframe.srcdoc = facets_html;\n",
       "         facets_iframe.id = \"\";\n",
       "         setTimeout(() => {\n",
       "           facets_iframe.setAttribute('height', facets_iframe.contentWindow.document.body.offsetHeight + 'px')\n",
       "         }, 1500)\n",
       "         </script>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with metadata.Metadata(connection_config) as store:\n",
    "    stats_artifacts = store.get_artifacts_by_type(ExampleStatistics.TYPE_NAME)\n",
    "\n",
    "stats_path = stats_artifacts[-1].uri\n",
    "train_stats_file = os.path.join(stats_path, 'train', 'stats_tfrecord')\n",
    "eval_stats_file = os.path.join(stats_path, 'eval', 'stats_tfrecord')\n",
    "train_stats = tfdv.load_statistics(train_stats_file)\n",
    "eval_stats = tfdv.load_statistics(eval_stats_file)\n",
    "tfdv.visualize_statistics(lhs_statistics=eval_stats, rhs_statistics=train_stats,\n",
    "                          lhs_name='EVAL_DATASET', rhs_name='TRAIN_DATASET')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualize model evaluations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:absl:MetadataStore with DB connection initialized\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b294eb92cab7450e87e3cb906ed5f629",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "SlicingMetricsViewer(config={'weightedExamplesColumn': 'example_count'}, data=[{'slice': 'Wilderness_Area:Cach…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with metadata.Metadata(connection_config) as store:\n",
    "    model_eval_artifacts = store.get_artifacts_by_type(ModelEvaluation.TYPE_NAME)\n",
    "\n",
    "model_eval_path = model_eval_artifacts[-1].uri\n",
    "eval_result = tfma.load_eval_result(model_eval_path)\n",
    "tfma.view.render_slicing_metrics(\n",
    "    eval_result, slicing_column='Wilderness_Area')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submit a pipeline run to Managed Pipelines\n",
    "\n",
    "### Create custom docker image\n",
    "\n",
    "Write the Dockerfile."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting Dockerfile\n"
     ]
    }
   ],
   "source": [
    "%%writefile Dockerfile\n",
    "FROM gcr.io/caip-pipelines-assets/tfx:latest\n",
    "WORKDIR /pipeline\n",
    "COPY ./*.py ./\n",
    "ENV PYTHONPATH=\"/pipeline:${PYTHONPATH}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the Skaffold build configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "apiVersion: skaffold/v2beta3\n",
      "kind: Config\n",
      "metadata:\n",
      "  name: my-pipeline\n",
      "build:\n",
      "  artifacts:\n",
      "  - image: 'gcr.io/mlops-dev-env/caip-tfx-custom'\n",
      "    context: .\n",
      "    docker:\n",
      "      dockerfile: Dockerfile\n",
      "  tagPolicy:\n",
      "    envTemplate:\n",
      "      template: \"{{.IMAGE_NAME}}:latest\"\n"
     ]
    }
   ],
   "source": [
    "TAG = 'latest'\n",
    "SK_TEMPLATE = \"{{{{.IMAGE_NAME}}}}:{}\".format(TAG)\n",
    "CUSTOM_IMAGE = f'gcr.io/{PROJECT_ID}/caip-tfx-custom'\n",
    "\n",
    "skaffold_template = f\"\"\"\n",
    "apiVersion: skaffold/v2beta3\n",
    "kind: Config\n",
    "metadata:\n",
    "  name: my-pipeline\n",
    "build:\n",
    "  artifacts:\n",
    "  - image: '{CUSTOM_IMAGE}'\n",
    "    context: .\n",
    "    docker:\n",
    "      dockerfile: Dockerfile\n",
    "  tagPolicy:\n",
    "    envTemplate:\n",
    "      template: \"{{SK_TEMPLATE}}\"\n",
    "\"\"\"\n",
    "\n",
    "with open('skaffold.yaml', 'w') as f:\n",
    "    f.write(skaffold_template.format(**globals()))\n",
    "\n",
    "!cat skaffold.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build and push the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating tags...\n",
      " - gcr.io/mlops-dev-env/caip-tfx-custom -> WARN[0000] {{.IMAGE_NAME}} is deprecated, envTemplate's template should only specify the tag value. See https://skaffold.dev/docs/pipeline-stages/taggers/ \n",
      "gcr.io/mlops-dev-env/caip-tfx-custom:latest\n",
      "Checking cache...\n",
      " - gcr.io/mlops-dev-env/caip-tfx-custom: Not found. Building\n",
      "Building [gcr.io/mlops-dev-env/caip-tfx-custom]...\n",
      "Sending build context to Docker daemon  14.85kB\n",
      "Step 1/4 : FROM gcr.io/caip-pipelines-assets/tfx:latest\n",
      "latest: Pulling from caip-pipelines-assets/tfx\n",
      "\n",
      "bd47987755ba: Pulling fs layer \n",
      "831c222b21d8: Pulling fs layer \n",
      "3c2cba919283: Pulling fs layer \n",
      "e378d88a5f59: Pulling fs layer \n",
      "df37508d2f5c: Pulling fs layer \n",
      "c28e7cc900d1: Pulling fs layer \n",
      "9019978541a7: Pulling fs layer \n",
      "dd7b5234f4fa: Pulling fs layer \n",
      "ce0400f6fa85: Pulling fs layer \n",
      "2bd9ab2a8520: Pulling fs layer \n",
      "Digest: sha256:0f16dd803877af4db04398df24e22bb4c0a747a63b31bce3689a302e1b000729\n",
      "Status: Downloaded newer image for gcr.io/caip-pipelines-assets/tfx:latest\n",
      " ---> 19c14dda2bb5\n",
      "Step 2/4 : WORKDIR /pipeline\n",
      " ---> Running in 605fe6934471\n",
      " ---> 73280faa1be8\n",
      "Step 3/4 : COPY ./*.py ./\n",
      " ---> 1157ab40c72a\n",
      "Step 4/4 : ENV PYTHONPATH=\"/pipeline:${PYTHONPATH}\"\n",
      " ---> Running in e29049a00c58\n",
      " ---> 4e64928596c3\n",
      "Successfully built 4e64928596c3\n",
      "Successfully tagged gcr.io/mlops-dev-env/caip-tfx-custom:latest\n",
      "The push refers to repository [gcr.io/mlops-dev-env/caip-tfx-custom]\n",
      "\n",
      "ed8503093cd8: Preparing \n",
      "096a31859079: Preparing \n",
      "040e39b76df7: Preparing \n",
      "34d223592bf6: Preparing \n",
      "076274ac0c03: Preparing \n",
      "d73a82f851f0: Preparing \n",
      "4058ae03fa32: Preparing \n",
      "e3437c61d457: Preparing \n",
      "84ff92691f90: Preparing \n",
      "54b00d861a7a: Preparing \n",
      "84ff92691f90: Preparing \n",
      "c4e66be694ce: Preparing \n",
      "latest: digest: sha256:b58de098269013e4f600a34e84bd7944eb73a994e8aee7db9c8dac32248a9ea8 size: 3264\n"
     ]
    }
   ],
   "source": [
    "!skaffold build"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_name = 'covertype-end-to-end'\n",
    "components = [example_gen, \n",
    "              statistics_gen, \n",
    "              schema_gen,\n",
    "              example_validator,\n",
    "              transform,\n",
    "              trainer,\n",
    "              model_resolver,\n",
    "              model_analyzer,\n",
    "              infra_validator,\n",
    "              pusher]\n",
    "\n",
    "pipeline = Pipeline(\n",
    "    pipeline_name=pipeline_name,\n",
    "    pipeline_root=f'{GCS_PIPELINE_ROOT}/{pipeline_name}',\n",
    "    components=components\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configure Manage Pipelines runner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_display_name = 'Covertype Classifier Training'\n",
    "\n",
    "runner = ai_platform_pipelines_dag_runner.AIPlatformPipelinesDagRunner(\n",
    "    config=ai_platform_pipelines_dag_runner.AIPlatformPipelinesDagRunnerConfig(\n",
    "        project_id=PROJECT_ID,\n",
    "        display_name=pipeline_display_name,\n",
    "        default_image=CUSTOM_IMAGE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on method run in module tfx.orchestration.ai_platform_pipelines.ai_platform_pipelines_dag_runner:\n",
      "\n",
      "run(pipeline: tfx.orchestration.pipeline.Pipeline, api_key: str, endpoint: Union[str, NoneType] = None) -> str method of tfx.orchestration.ai_platform_pipelines.ai_platform_pipelines_dag_runner.AIPlatformPipelinesDagRunner instance\n",
      "    Compiles a pipeline DSL object and runs it on CAIP service.\n",
      "    \n",
      "    Args:\n",
      "      pipeline: TFX pipeline object.\n",
      "      api_key: API key to access the CAIP pipeline endpoint. Please refer to\n",
      "        [here](https://developers.google.com/places/web-service/get-api-key)\n",
      "          regarding how to create one. Only API key associated with whitelisted\n",
      "          GCP project can access CAIP pipeline service before its launch.\n",
      "          AIPlatformPipelinesDagRunner().run() will raise error without\n",
      "          providing an API key in this config.\n",
      "      endpoint: CAIP pipelines service endpoint. Defaults to\n",
      "        'alpha-ml.googleapis.com'.\n",
      "    \n",
      "    Returns:\n",
      "      Full CAIP pipelines job name.\n",
      "    Raises:\n",
      "      RuntimeError: if CAIP pipeline service returns unexpected response or\n",
      "      empty job name.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(runner.run)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submit run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key = ''\n",
    "\n",
    "runner.run(pipeline, api_key=api_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next steps\n",
    "\n",
    "This concludes your introductory walthrough through TFX pipeline components. In the lab, you used TFX to analyze, understand, and pre-process the dataset and train, analyze, validate, and deploy a multi-class classification model to predict the type of forest cover from cartographic features. You utilized a TFX Interactive Context for prototype development of a TFX pipeline directly in a Jupyter notebook. Next, you worked with the TFDV library to modify your dataset schema to add feature constraints to catch data anamolies that can negatively impact your model's performance. You utilized TFT library for feature proprocessing for consistent feature transformations for your model at training and serving time. Lastly, using the TFMA library, you added model performance constraints to ensure you only push more accurate models than previous runs to production.\n",
    "\n",
    "\n",
    "The next labs in the series will guide through developing a TFX pipeline, deploying and running the pipeline on **AI Platform Pipelines** and automating the pipeline build and deployment processes with **Cloud Build**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## License"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=-1>Licensed under the Apache License, Version 2.0 (the \\\"License\\\");\n",
    "you may not use this file except in compliance with the License.\n",
    "You may obtain a copy of the License at [https://www.apache.org/licenses/LICENSE-2.0](https://www.apache.org/licenses/LICENSE-2.0)\n",
    "\n",
    "Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an \\\"AS IS\\\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.  See the License for the specific language governing permissions and limitations under the License.</font>"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "name": "tf2-2-3-gpu.2-3.m55",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-2-3-gpu.2-3:m55"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
